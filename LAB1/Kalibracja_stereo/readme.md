# ğŸ“¸ Stereokalibracja kamer

## ğŸ¯ Cel Ä‡wiczenia
* uzyskanie macierzy kalibracyjnej stereokamery
* wyznaczenie punktÃ³w 3D na podstawie punktÃ³w 2D
* wyznaczenie transformacji miÄ™dzy ukladami wspÃ³Å‚rzÄ™dnych
* wyznaczenie punktÃ³w 3d w dwÃ³ch ukÅ‚adach wspÃ³Å‚rzÄ™dnych dla obiektu trÃ³jwymiarowego
---

## ğŸ“¦ Wymagania
Aby uruchomiÄ‡ skrypt, naleÅ¼y mieÄ‡ zainstalowane wymagane pakiety:

```
pip install -r requirements.txt
```
Wymagane funkcje do dalszych analiz znajdujÄ… siÄ™ w bibliotece
```
lab1_lib_.py
```
ğŸ” Przed przystapieniem do Ä‡wiczenia warto zapoznaÄ‡ siÄ™ wstÄ™pnie jakie gotowe funkcjonalnoÅ›ci sÄ… dostÄ™pne 


# ğŸ“‡ Macierze kalibracyjne stereokamery
Kalibracja kamer stereo w OpenCV na podstawie plikÃ³w JSON z parametrami pojedynczych kamer
Kalibracja kamer stereo pozwala na uzyskanie relacji geometrycznej miÄ™dzy dwiema kamerami, co jest kluczowe w aplikacjach takich jak rekonstrukcja 3D czy estymacja gÅ‚Ä™bi. JeÅ›li masz juÅ¼ pliki JSON zawierajÄ…ce parametry pojedynczych kamer, moÅ¼na je wykorzystaÄ‡ do przeprowadzenia kalibracji stereo.

Funkcja ```calib_stereo_from_jsons()``` przyjmuje jako argument dwa pliki .json z macierzami pojedynczej kalibracji kamery
przykÅ‚ad wywoÅ‚ania funkcji: 

```calib_stereo_from_jsons(matrix_cam_left.json, matrix_cam_right.json```

funkcja zwraca plik .json o strukturze:
```json lines
 jsonStruct = {
        "retS": "ret",
        "K1": "mtxL",
        "D1": "distL",
        "K2": "mtxR",
        "D2": "distR",
        "R": "R",
        "T": "T",
        "E": "E",
        "F": "F",
        "rvecsL": "[r.tolist() for r in rvecsL]",
        "rvecsR": "[r.tolist() for r in rvecsR]",
        "square_size": "square_sizeL"
    }
```
* ***ret***	- Åšredni bÅ‚Ä…d reprojekcji (im mniejszy, tym lepiej)
* ***K1, K2*** - Macierze kamer (ogniskowa, punkt gÅ‚Ã³wny)
* ***D1, D2*** - WspÃ³Å‚czynniki dystorsji (radialna, tangencjalna)
* ***R*** - Macierz rotacji opisujÄ…ca obrÃ³t prawej kamery wzglÄ™dem lewej. JeÅ›li kamery sÄ… idealnie ustawione rÃ³wnolegle, powinna to byÄ‡ macierz jednostkowa. 
MoÅ¼na jÄ… przeksztaÅ‚ciÄ‡ na kÄ…ty Eulera, aby okreÅ›liÄ‡, jak bardzo kamery sÄ… obrÃ³cone wzglÄ™dem siebie.
* ***T*** - Wektor translacji opisujÄ…cy przesuniÄ™cie prawej kamery wzglÄ™dem lewej. WartoÅ›Ä‡ jest wyraÅ¼ona w tej samej jednostce co objectPoints (zwykle milimetry lub centymetry). Dla poprawnej kalibracji wartoÅ›Ä‡ T[0] powinna byÄ‡ bliska rzeczywistej odlegÅ‚oÅ›ci miÄ™dzy kamerami.
* ***E*** - Macierz epipolarna (Essential Matrix) opisuje relacjÄ™ geometrycznÄ… miÄ™dzy punktami w obu obrazach w przestrzeni 3D. Stosowana w przypadku znanej macierzy kamery do obliczeÅ„ pozycji punktÃ³w 3D.
* ***F*** - Macierz fundamentalna (Fundamental Matrix) Macierz fundamentalna (Fundamental Matrix) opisuje zaleÅ¼noÅ›ci miÄ™dzy punktami w dwÃ³ch obrazach bez znajomoÅ›ci parametrÃ³w kamer. UÅ¼ywana w klasycznych metodach dopasowania stereowizji.

## Wyznaczanie punktÃ³w 3D dla markerÃ³w ArUco

Dla obrazÃ³w z widocznymi markerami ArUco zostanÄ… wykonane dwie operacje
* wykrycie lewego naroÅ¼nika i zapisanie jego wspÃ³Å‚rzÄ™dnych

```
pathL,pathR = r"marker_left.jpg", r"marker_right.jpg"
imageL,imageR = cv2.imread(pathL), cv2.imread(pathR)
imgL, paramsL = aruco_detect_left_corner(imageL)
imgR, paramsR = aruco_detect_left_corner(imageR) # umieÅ›Ä‡ otrzymane obrazy w sprawozdaniu - sprawdÅº poprawnoÅ›Ä‡ wyznaczenia naroÅ¼y
cv2.imwrite("arucoL.jpg",imgL)
cv2.imwrite("arucoR.jpg",imgR)
# ======== instrukcje zwiÄ…zane z konfiguracjÄ… kamery
...
# =======
# zapis wspÃ³Å‚rzÄ™dnych do dalszych analiz
save_marker2json(paramsL,"camL")
save_marker2json(paramsR,"camR")
P_rawL,P_rawR = sortedRawPoints("camL.json","camR.json") # sortowanie punktÃ³w dla odpowiadajÄ…cych sobie ID PUNKTY HOMOLOGICZNE
```
### WaÅ¼noÅ›Ä‡ sortowania punktÃ³w po kluczu ID - ```sortedRawPoints```
Ostatnia operacja sortowania punktÃ³w po kluczu ID jest kluczowa dla prawidÅ‚owej analizy danych. Aby wyniki obliczeÅ„ byÅ‚y wiarygodne, zestaw danych musi byÄ‡ uporzÄ…dkowany. Posiadanie punktÃ³w homologicznych 2D oraz odpowiadajÄ…cych im punktÃ³w 3D w ukÅ‚adzie wspÃ³Å‚rzÄ™dnych kamery jest niezbÄ™dne do uzyskania poprawnych wynikÃ³w.

**PorzÄ…dek punktÃ³w:** JeÅ›li punkty 2D z kamer 1 i 2, a takÅ¼e ich odpowiedniki w przestrzeni 3D, nie bÄ™dÄ… uporzÄ…dkowane w ten sam sposÃ³b (tj. w tej samej kolejnoÅ›ci), proces triangulacji bÄ™dzie miaÅ‚ trudnoÅ›ci z przypisaniem odpowiednich punktÃ³w miÄ™dzy kamerami. MoÅ¼e to prowadziÄ‡ do nieprawidÅ‚owych wynikÃ³w, gdzie obliczone punkty 3D nie odpowiadajÄ… rzeczywistym pozycjom w przestrzeni.

Kluczowe uwagi:<br>
* Sprawdzanie zgodnoÅ›ci punktÃ³w: Zawsze przed przystÄ…pieniem do obliczeÅ„ naleÅ¼y upewniÄ‡ siÄ™, Å¼e punkty homologiczne (2D) sÄ… poprawnie sparowane z ich odpowiednikami w przestrzeni 3D. Jest to szczegÃ³lnie waÅ¼ne w przypadku duÅ¼ych zestawÃ³w danych, gdzie rÄ™czne sprawdzenie kaÅ¼dego punktu moÅ¼e byÄ‡ trudne. Warto korzystaÄ‡ z odpowiednich narzÄ™dzi lub algorytmÃ³w, ktÃ³re umoÅ¼liwiajÄ… automatyczne dopasowanie punktÃ³w po ID lub innym kluczu.

* BÅ‚Ä…d w dopasowaniu punktÃ³w: PominiÄ™cie tego kroku sprawi, Å¼e triangulacja nie bÄ™dzie prawidÅ‚owa, a uzyskane punkty 3D bÄ™dÄ… rozmieszczone w sposÃ³b niezgodny z rzeczywistoÅ›ciÄ…, co negatywnie wpÅ‚ynie na dalsze analizy i obliczenia.

**Podsumowanie:**<br> 
 **ZAWSZE przed przeprowadzeniem analizy, sprawdÅº porzÄ…dek punktÃ³w i upewnij siÄ™, Å¼e punkty 2D i ich odpowiedniki 3D sÄ… poprawnie sparowane. To kluczowy krok, ktÃ³ry zapewnia poprawnoÅ›Ä‡ wynikÃ³w. Przestrzeganie tej zasady zapewnia stabilnoÅ›Ä‡ i dokÅ‚adnoÅ›Ä‡ caÅ‚ego procesu triangulacji oraz dalszych analiz.**

****

PowstaÅ‚y plik .json ma strukturÄ™:


```json lines
{
  "coordinates": [["x1","y1"],["x2","y2"]]
  "ids": ["id_1","id_2"]
}
```

<div align="center">
  <img src="Images/arucoL.jpg" alt="Aruco IDs" title="example frame in IDs" width="300">
</div>

* Wczytanie parametrÃ³w stereo-kalibracji 

```
calibData = calibDataFromFileJson("matrix_cam.json") # wczytanie macierzy kalibracyjnej
points_Camera_3D = get3DpointsFrom2Ddata_full(calibData, P_rawL, P_rawR, type="list") #wyznaczenie punktÃ³w 3D w ukÅ‚Ä…dzie wspÃ³Å‚rzÄ™dnych kamery
```
* wyznaczenie punktÃ³w 3D rogÃ³w w ukÅ‚adzie wspÃ³Å‚rzÄ™dnych kamery
* 

## Funkcja `points_3d_from_data` - WyjaÅ›nienie

Funkcja `points_3d_from_data` przeksztaÅ‚ca dwa zestawy punktÃ³w 2D (z lewej i prawej kamery) na wspÃ³Å‚rzÄ™dne 3D w przestrzeni. UÅ¼ywa parametrÃ³w kalibracyjnych z pliku JSON oraz techniki triangulacji, czyli przeciÄ™cia promieni rzutujÄ…cych z obu kamer.

---

### 1 **Pobranie parametrÃ³w kalibracji**
```
K1 = np.array(calib_object["K1"])  # Macierz wewnÄ™trzna kamery 1
D1 = np.array(calib_object["D1"])  # WspÃ³Å‚czynniki dystorsji kamery 1
K2 = np.array(calib_object["K2"])  # Macierz wewnÄ™trzna kamery 2
D2 = np.array(calib_object["D2"])  # WspÃ³Å‚czynniki dystorsji kamery 2
R = np.array(calib_object["R"])    # Macierz rotacji miÄ™dzy kamerami
T = np.array(calib_object["T"])    # Wektor translacji (przesuniÄ™cia) miÄ™dzy kamerami
```

### 2. Obliczenie macierzy projekcji P1 i P2
```
def projectionMatrix(mtx1, mtx2, R, T):
    RT1 = np.concatenate([np.eye(3), [[0], [0], [0]]], axis=-1)
    P1 = mtx1 @ RT1  # projection matrix for C1
    RT2 = np.concatenate([R, T], axis=-1)
    P2 = mtx2 @ RT2  # projection matrix for C2
    return P1, P2
```
* P1 to macierz projekcji kamery 1.
* P2 to macierz projekcji kamery 2, uwzglÄ™dniajÄ…ca rotacjÄ™ i translacjÄ™ miÄ™dzy kamerami.

### 3. Triangulacja punktÃ³w 3D `DLT()`

Funkcja DLT (Direct Linear Transformation) sÅ‚uÅ¼y do triangulacji punktu 3D na podstawie jego rzutÃ³w (punktÃ³w 2D) na dwÃ³ch obrazach uzyskanych z dwÃ³ch rÃ³Å¼nych kamer.
```
def DLT(P1, P2, point1, point2):
    A = [point1[1] * P1[2, :] - P1[1, :],
         P1[0, :] - point1[0] * P1[2, :],
         point2[1] * P2[2, :] - P2[1, :],
         P2[0, :] - point2[0] * P2[2, :]
         ]
    A = np.array(A).reshape((4, 4))
    B = A.transpose() @ A
    U, s, Vh = linalg.svd(B, full_matrices=False)
    return Vh[3, 0:3] / Vh[3, 3]
```

## Finalnie funkcja `points_3d_from_data` zwraca punkty w przestrzeni trÃ³jwymiarowej
```
def points_3d_from_data(calibData, listPoints2D_1, listPoints2D_2, type="list"):
    CM1 = calibData["K1"]
    CM2 = calibData["K2"]
    R = calibData["R"]
    T = calibData["T"]
    uvs1, uvs2 = listImgPoints2array(listPoints2D_1, listPoints2D_2)
    P1, P2 = projectionMatrix(CM1, CM2, R, T)
    points3D = getPoints3D(uvs1, uvs2, P1, P2, type=type)
    return points3D
```
### ğŸ” Podsumowanie
ğŸ”¹ *WejÅ›cie*:
calib_object: parametry kalibracji (z pliku JSON).

* points2d_1: lista punktÃ³w 2D z lewej kamery.

* points2d_2: lista punktÃ³w 2D z prawej kamery.

ğŸ”¹ *DziaÅ‚anie*:
Pobranie parametrÃ³w kalibracji (K1, D1, K2, D2, R, T).

* Konwersja punktÃ³w 2D na NumPy.

* Obliczenie macierzy projekcji P1 i P2.

* Triangulacja 

* PrzeksztaÅ‚cenie na wspÃ³Å‚rzÄ™dne (x, y, z).

ğŸ”¹ WyjÅ›cie:
* Lista punktÃ³w 3D w przestrzeni (np. wspÃ³Å‚rzÄ™dne w metrach, jeÅ›li kalibracja jest poprawna).
```
# Wczytanie danych z pliku JSON
with open("calibData.json", "r") as f:
    calib_object = json.load(f)

# PrzykÅ‚adowe punkty z dwÃ³ch kamer
points2d_1 = [[100, 200], [150, 250], [300, 400]]
points2d_2 = [[105, 205], [155, 255], [305, 405]]

# Obliczenie wspÃ³Å‚rzÄ™dnych 3D
points3D = points_3d_from_data(calib_object, points2d_1, points2d_2)

# WyÅ›wietlenie wynikÃ³w
print(points3D)
PrzykÅ‚adowy wynik:

[[ 1.2  0.5  3.8]
 [ 1.5  0.6  4.0]
 [ 2.0  1.0  5.2]]
KaÅ¼dy wiersz [X, Y, Z] to jeden punkt w przestrzeni 3D. ğŸš€
```
## Wyznaczenie punktÃ³w 3D w ukÅ‚adzie wspÃ³Å‚rzÄ™dnych tablicy

Obiekt testowy z markerami ma okreÅ›lone wspÃ³Å‚rzÄ™dne wzglÄ™dem siebie i tablicy. Do dalszych analiz wymagane jest zapisanie
tych wspÃ³Å‚rzÄ™dnych np. do pliku. Pozwoli to na sprawdzenie poprawnoÅ›ci koÅ„cowych obliczeÅ„. 
WspÃ³Å‚rzÄ™dne 3D zostaÅ‚y zapisane w milimetrach - sÄ… to wartoÅ›ci staÅ‚e, na tym etapie proszÄ™ ich nie zmieniaÄ‡. 
```
points = [[9.6,11.5,0],[117.6,11.5,0],[225.6,11.5,0],[9.6,139.5,0],[117.6,139.5,0],[225.6,139.5,0]] #[mm] punkty 3D w ukÅ‚adzie wspÃ³Å‚rzÄ™dnych tablicy [x,y,0]
ids = [0,67,14,46,79,63] # ID markerÃ³w odpowiadajÄ…ce wspÃ³Å‚rzÄ™dnym w tablicy points
save_3d_WP(points, ids,"") #zapis punktÃ³w 3D w ukÅ‚adzie wspÃ³Å‚rzÄ™dnych tablicy
l1,l2,points_world_3d = sorted_2d_3d_Points("camL.json","camR.json","3d_world_.json") #sortowanie punktÃ³w 2D i 3D po ID
```
## Funkcja `supplementary_data`

Funkcja supplementary_data przetwarza dane kalibracyjne i przestrzenne, aby:

âœ… ObliczyÄ‡ macierze transformacji miÄ™dzy ukÅ‚adami wspÃ³Å‚rzÄ™dnych (Å›wiatowy â†” kamera).

âœ… WyznaczyÄ‡ pozycjÄ™ i orientacjÄ™ kamer na podstawie punktÃ³w referencyjnych.

âœ… ObliczyÄ‡ odlegÅ‚oÅ›ci punktÃ³w od kamer.


### 1.  Obliczenie macierzy transformacji
Funkcja wylicza dwie macierze transformacji:

T_WRL2CAM â†’ Transformacja ze Å›wiata rzeczywistego (WRL) do ukÅ‚adu kamery.

T_CAM2WRL â†’ Transformacja z ukÅ‚adu kamery do Å›wiata rzeczywistego.
Obie macierze sÄ… obliczane za pomocÄ…:
```
T_WRL2CAM = getTransformationMatrix_WRL2CAM(points_world_3d, points_camera_3d)
T_CAM2WRL = getTransformationMatrix_CAM2WRL(points_camera_3d, points_world_3d)
```
Funkcje te przeksztaÅ‚cajÄ… ukÅ‚ad wspÃ³Å‚rzÄ™dnych na podstawie znanych punktÃ³w 3D w dwÃ³ch ukÅ‚adach.

### 2. Wczytanie parametrÃ³w kamery
Pobierane sÄ… macierze K (parametry wewnÄ™trzne) oraz D (znieksztaÅ‚cenia soczewki) dla obu kamer:

```K1 = np.array(calibdata["K1"])
K2 = np.array(calibdata["K2"])
dist1 = np.array(calibdata["D1"])
dist2 = np.array(calibdata["D2"])
```

K1, K2 â†’ Macierze wewnÄ™trzne (parametry kamery).

dist1, dist2 â†’ WspÃ³Å‚czynniki znieksztaÅ‚ceÅ„ optycznych.

### 3. Obliczenie pozycji kamer w ukÅ‚adzie wizyjnym

Za pomocÄ… calculatePoseCameraInVisinSystem obliczana jest orientacja i pozycja kamer:
```
val, r1, t1, posCAM1_vs, rotCAM1_vs = calculatePoseCameraInVisinSystem(points_camera_3d, p2d_left, K1, dist1)
val, r2, t2, posCAM2_vs, rotCAM2_vs = calculatePoseCameraInVisinSystem(points_camera_3d, p2d_right, K2, dist2)
```
r1, r2 â†’ Wektory obrotu kamer.
t1, t2 â†’ Wektory translacji kamer.

posCAM1_vs, posCAM2_vs â†’ Pozycje kamer w ukÅ‚adzie wizyjnym.

rotCAM1_vs, rotCAM2_vs â†’ Orientacje kamer w ukÅ‚adzie wizyjnym.

ğŸ“Œ WyÅ›wietlenie orientacji kamer
```
print(f"wektor obrotu kamery lewej {rotCAM1_vs} ")
print(f"wektor obrotu kamery prawej {rotCAM2_vs} ")
```
### 4. Obliczenie odlegÅ‚oÅ›ci punktÃ³w od kamer
Za pomocÄ… calculate_distances funkcja oblicza, jak daleko od kamer znajdujÄ… siÄ™ punkty:

```
dCAM1_vs = calculate_distances(posCAM1_vs, points_camera_3d)
dCAM2_vs = calculate_distances(posCAM2_vs, points_camera_3d)
```
ğŸ“Œ WyÅ›wietlenie odlegÅ‚oÅ›ci
```
print(f"odlegÅ‚oÅ›Ä‡ punktu od kamery lewej {dCAM1_vs} mm")
print(f"odlegÅ‚oÅ›Ä‡ punktu od kamery prawej {dCAM2_vs} mm")
```
ğŸ“¤ Zwracane wartoÅ›ci
```
return T_WRL2CAM, T_CAM2WRL, r1, t1, r2, t2
âœ… T_WRL2CAM â€“ Macierz transformacji Å›wiat â†’ kamera
âœ… T_CAM2WRL â€“ Macierz transformacji kamera â†’ Å›wiat
âœ… r1, t1 â€“ Rotacja i translacja kamery lewej
âœ… r2, t2 â€“ Rotacja i translacja kamery prawej
```

ğŸ“Œ Podsumowanie
ğŸ”¹ Konwertuje ukÅ‚ady wspÃ³Å‚rzÄ™dnych (Å›wiat â†” kamera).
ğŸ”¹ Oblicza pozycjÄ™ i orientacjÄ™ kamer na podstawie punktÃ³w odniesienia.
ğŸ”¹ Wylicza odlegÅ‚oÅ›ci punktÃ³w 3D od kamer.
ğŸ”¹ Zwraca kluczowe parametry transformacji, ktÃ³re mogÄ… byÄ‡ uÅ¼yte np. do rekonstrukcji 3D.

To kluczowa funkcja do analizy ukÅ‚adu kamer w stereowizji i kalibracji! ğŸš€

### Funkcja `check_presision`
Funkcja `check_transformation` sprawdza poprawnoÅ›Ä‡ transformacji 2D-3D oraz 3D-2D, porÃ³wnujÄ…c uzyskane wyniki z wartoÅ›ciami oczekiwanymi. Na podstawie danych kalibracyjnych kamery oraz punktÃ³w 3D i 2D obliczane sÄ… rÃ³Å¼nice miÄ™dzy wartoÅ›ciami obliczonymi a rzeczywistymi.

---
DziaÅ‚anie funkcji:
1. **Wczytywanie danych kalibracyjnych:**

   - Funkcja wczytuje dane kalibracyjne z pliku JSON, ktÃ³re zawierajÄ… macierze kamery, dystorsje, rotacje, translacje i macierze transformacji.

    - Wczytane dane sÄ… przeksztaÅ‚cane na odpowiednie tablice NumPy.

2. **Przygotowanie punktÃ³w wejÅ›ciowych:**

    - Funkcja przyjmuje punkty 3D (object_3d_point) oraz punkty 2D dla lewej i prawej kamery (P_rawL, P_rawR).

    - PrzeksztaÅ‚ca dane wejÅ›ciowe na tablice NumPy, ktÃ³re bÄ™dÄ… uÅ¼yte w dalszych obliczeniach.

3. **Obliczanie punktÃ³w 3D z 2D:**

    - Funkcja oblicza punkty 3D w ukÅ‚adzie Å›wiata na podstawie punktÃ³w 2D z kamer oraz danych kalibracyjnych za pomocÄ… funkcji get_3DWorld_from_2DImage.

4. **Obliczanie punktÃ³w 2D z 3D:**

    - Funkcja oblicza odwrotnoÅ›Ä‡ operacji â€” oblicza punkty 2D na obrazach kamer na podstawie punktÃ³w 3D w ukÅ‚adzie Å›wiata za pomocÄ… funkcji get_2DImage_from_3DWorld.

5. **PorÃ³wnanie wynikÃ³w:**

    - Funkcja oblicza rÃ³Å¼nice pomiÄ™dzy rzeczywistymi punktami 3D a wyliczonymi punktami, a takÅ¼e pomiÄ™dzy punktami 2D wyliczonymi na podstawie 3D a oryginalnymi punktami 2D.

    - Wyniki sÄ… wyÅ›wietlane na konsoli w jednostkach milimetrÃ³w (dla rÃ³Å¼nic w przestrzeni 3D) oraz pikselach (dla rÃ³Å¼nic w przestrzeni 2D).

6. **Wyniki:**
   - Funkcja zwraca rÃ³Å¼nice miÄ™dzy rzeczywistymi a wyliczonymi punktami:

    - RÃ³Å¼nice w przestrzeni 3D (w mm):

    **IMG > WRL - rÃ³Å¼nice miÄ™dzy rzeczywistymi punktami 3D a obliczonymi.**

    - RÃ³Å¼nice w przestrzeni 2D (w px):

    **WRL > IMG - rÃ³Å¼nice miÄ™dzy punktami 2D obliczonymi na podstawie 3D a rzeczywistymi punktami 2D.**

### ğŸ”Podsumowanie
Funkcje ```check_precision``` oraz ```supplementary_data``` umoÅ¼liwiajÄ… generowanie danych kalibracyjnych kamer stereo, obliczanie transformacji miÄ™dzy ukÅ‚adami koordynatÃ³w oraz sprawdzanie dokÅ‚adnoÅ›ci transformacji 3D-2D i 2D-3D. DziÄ™ki nim moÅ¼na sprawdziÄ‡, czy obliczane punkty w przestrzeni 3D odpowiadajÄ… punktom 2D na obrazach kamer, co jest kluczowe przy analizie i weryfikacji wynikÃ³w kalibracji kamery.

### wizualizacja obliczonych punktÃ³w 2D 

Funkcja ```show_data_image``` przedstawia graficznÄ… realizacjÄ™ przeksztaÅ‚ceÅ„ punktÃ³w 

<p align="center">
  <img src="Images/punkty_triangulacja.jpg"/>
</p>


### wizualizacja obliczania odlegÅ‚oÅ›ci miÄ™dzy punktami w przestrzeni 

Funkcja ```draw_points_and_distances``` 

* oblicza wspÃ³Å‚rzÄ™dne 3D dla dwÃ³ch homologicznych punktÃ³w na obrazie (kaÅ¼dej z kamer)
* zwraca odlegÅ‚oÅ›Ä‡ miÄ™dzy punktami w mm

<p align="center">
  <img src="Images/stozki_odleglosc.jpg"/>
</p>