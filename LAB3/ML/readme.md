# Podstawy uczenia maszynowego

## :one: Skorzystanie z gotowego modelu 

W Ä‡wiczeniu zostanie przedstawione podstawowe dziaÅ‚anie modelu YOLO5.
w skrypcie `YOLO5_classes.py` znajdujÄ… siÄ™ obsÅ‚ugiwane przez model klasy obiektÃ³w. 
ObsÅ‚ugiwane klasy to np.:

```python 
names = {
  0: "person",
  1: "bicycle",
  2: "car",
  3: "motorcycle",
  4: "airplane",
  5: "bus",
  6: "train"
}
```

### Testowanie modelu na swoich danych
W skrypcie ```usage_custom_model.py``` znajduje siÄ™ podstawowy skrypt do wizualizacji wynikÃ³w
uzyskanych przez analizÄ™ obrazu uÅ¼ywajÄ…c model YOLO5. Przy pierwszym uÅ¼yciu model
naleÅ¼y pobraÄ‡ z oficjalnego repozytorium https://github.com/ultralytics/yolov5

### **skrypt `usage_custom_model.py`**
```python
import torch
model = torch.hub.load("ultralytics/yolov5", "yolov5s")  # Default: yolov5s
img = "example_image.jpg" # lub https://ultralytics.com/images/zidane.jpg"
results = model(img)
results.print()
results.show()
results.save() 
```
* `torch` Importuje bibliotekÄ™ PyTorch, ktÃ³ra jest podstawowÄ… bibliotekÄ… do pracy z sieciami neuronowymi w Pythonie. W tym przypadku jest wykorzystywana do zaÅ‚adowania modelu YOLOv5.
* `torch.hub.load()`: Funkcja ta pozwala na zaÅ‚adowanie modelu z repozytorium GitHub. W tym przypadku Å›ciÄ…gamy model YOLOv5 bezpoÅ›rednio z repozytorium ultralytics/yolov5. UÅ¼ywajÄ…c torch.hub, moÅ¼emy szybko zaÅ‚adowaÄ‡ model bez koniecznoÅ›ci pobierania go lokalnie.
* `"ultralytics/yolov5"`: To repozytorium GitHub, z ktÃ³rego jest Å‚adowany model YOLOv5.
* `"yolov5s"`: Jest to wersja modelu YOLOv5, ktÃ³rej chcemy uÅ¼yÄ‡. YOLOv5 ma rÃ³Å¼ne wersje: yolov5n (najmniejsza), yolov5s (small), yolov5m (medium), yolov5l (large), yolov5x (extra-large). Model yolov5s jest najczÄ™Å›ciej uÅ¼ywany, poniewaÅ¼ zapewnia dobry kompromis miÄ™dzy szybkoÅ›ciÄ… a dokÅ‚adnoÅ›ciÄ….
* `img`: Zmienna przechowuje adres URL do obrazu, ktÃ³ry bÄ™dzie uÅ¼yty do wykrywania obiektÃ³w. W tym przypadku jest to przykÅ‚adowy obraz Zidane udostÄ™pniony przez twÃ³rcÃ³w YOLOv5. MoÅ¼esz zastÄ…piÄ‡ ten URL lokalnym plikiem obrazka, podajÄ…c odpowiedniÄ… Å›cieÅ¼kÄ™ do pliku w swoim systemie.
* `model(img)` :Przekazuje obraz do modelu, aby wykonaÄ‡ detekcjÄ™ obiektÃ³w. Model YOLOv5 analizuje obraz, identyfikuje obiekty (np. osoby, samochody, zwierzÄ™ta) i zwraca wyniki w postaci obiektÃ³w zawierajÄ…cych informacje o wykrytych obiektach (np. wspÃ³Å‚rzÄ™dne bounding boxÃ³w, klasy obiektÃ³w, poziom pewnoÅ›ci).
* `results.print()`: WyÅ›wietla wyniki detekcji obiektÃ³w w konsoli. Na przykÅ‚ad, dla kaÅ¼dego wykrytego obiektu pokazuje:
* `results.save()`: Zapisuje wyniki detekcji do folderu na dysku. DomyÅ›lnie wyniki zostanÄ… zapisane w katalogu runs/detect/exp w folderze roboczym. W folderze tym znajdziesz obrazy z naniesionymi wynikami detekcji, a takÅ¼e pliki tekstowe zawierajÄ…ce szczegÃ³Å‚y dotyczÄ…ce wykrytych obiektÃ³w.

:file_folder: PrzykÅ‚ad struktury wynikÃ³w:

Po uruchomieniu kodu, w folderze runs/detect/exp mogÄ… pojawiÄ‡ siÄ™ nastÄ™pujÄ…ce pliki:

`example_image.jpg`: Obraz wejÅ›ciowy z naniesionymi ramkami wokÃ³Å‚ wykrytych obiektÃ³w.

`labels`: Plik z tekstowym opisem wykrytych obiektÃ³w (wspÃ³Å‚rzÄ™dne ramki, klasy, pewnoÅ›Ä‡).

### :bulb: Podsumowanie:
:heavy_check_mark: ZaÅ‚adowanie modelu YOLOv5: Model YOLOv5 jest Å‚adowany za pomocÄ… `torch.hub.load()` z repozytorium GitHub.

:heavy_check_mark: Przekazanie obrazu do modelu: Obraz jest analizowany przez model w celu detekcji obiektÃ³w.

:heavy_check_mark: WyÅ›wietlenie wynikÃ³w: MoÅ¼na wyÅ›wietliÄ‡ wyniki na konsoli oraz na obrazie.

:heavy_check_mark: Zapisanie wynikÃ³w: Wyniki detekcji sÄ… zapisywane w folderze roboczym.

:heavy_check_mark: Ten kod pozwala na Å‚atwe uruchomienie detekcji obiektÃ³w za pomocÄ… YOLOv5 w jednym kroku, bez koniecznoÅ›ci lokalnej instalacji i konfiguracji modelu.

---

## :two: Tworzenie dodatkowych zbiorÃ³w danych

Do przeprowadzenia fine-tuningu trzeba posiadaÄ‡ dodatkowy zbiÃ³r danych: **obrazy + etykiety** oraz stworzyÄ‡ plik **.yaml**

### **Dodatkowy zbiÃ³r danych obrazowych**
dodatkowy zbiÃ³r danych moÅ¼na stworzyÄ‡ samodzielnie lub pobraÄ‡ z internetu np. ze strony
* https://www.kaggle.com/datasets
W tej czÄ™Å›ci Ä‡wiczenia dodatkowym zbiorem obrazÃ³w bÄ™dÄ… zdjÄ™cia butÃ³w, ktÃ³re znajdujÄ… siÄ™ w folderze "shoes_datasheet"

* **Etykietowanie obrazÃ³w**
Do etykietowania obrazÃ³w w Ä‡wiczeniu bÄ™dzie wykorzystywany program "labelImg", ktÃ³ry w caÅ‚oÅ›ci znajduje siÄ™ pod tym linkiem: <br>
* https://github.com/HumanSignal/labelImg - na stronie znajduje siÄ™ szczegÃ³Å‚owa instrukcja jak korzystaÄ‡ z aplikacji <br>
Na potrzeby Ä‡wiczenia bÄ™dÄ… wykorzystywane najbardziej podstawowe funkcjonalnoÅ›ci. 
narzÄ™dzie do etykietowania uruchamiane jest za pomocÄ… skryptu 
* ***LAB3/ML/labelImg/labelImg.py***
uruchamiajÄ…c skrypt powinno pojawiÄ‡ siÄ™ okno :
<div align="center">
  <img src="Images\labeling.jpg" alt="Calib_table" title="example frame in calibration_table" width="300">
</div>
<div align="center">
  <img src="Images\folder.jpg" alt="Calib_table" title="example frame in calibration_table" width="300">
</div>

Wybieramy zakÅ‚adkÄ™ "Open Dir" i wybieramy folder "LAB3\ML\Shoes Dataset\Train\Sneaker"
teraz powinny byÄ‡ zaÅ‚adowane wszystkie elementy z folderu treningowego

* etykietowanie obiektÃ³w
CzÄ™Å›Ä‡ obrazÃ³w jest przygotowana do automatycznej detekcji butÃ³w np. rysunki z biaÅ‚ym tÅ‚em. Na zdjÄ™ciach o bardziej rÃ³Å¼norodnym tle
moÅ¼na wskazaÄ‡ interesujÄ…cy obiekt i nacisnÄ…Ä‡ save. 
<div align="center">
  <img src="Images\exp.jpg" alt="Calib_table" title="example frame in calibration_table" width="300">
</div>
* W bieÅ¼Ä…cym katalogu "train" powinien siÄ™ pojawiÄ‡ plik .txt 
o takiej samej nazwie jak zdjÄ™cie, ktÃ³re byÅ‚o etykietowane: 
<div align="center">
  <img src="Images\img_label.jpg" alt="Calib_table" title="example frame in calibration_table" width="300">
</div>
przykÅ‚adowa zawartoÅ›Ä‡ wygenerowanego pliku: <br>
**0 0.437198 0.563786 0.826087 0.460905**
### **Struktura pliku etykiety YOLO:**
* Nazwa pliku etykiety: KaÅ¼dy plik z etykietÄ… ma takÄ… samÄ… nazwÄ™ jak obraz, z tÄ… rÃ³Å¼nicÄ…, Å¼e zamiast rozszerzenia .jpg, .png lub innego rozszerzenia obrazu, uÅ¼ywa rozszerzenia .txt. Na przykÅ‚ad, jeÅ›li obraz nazywa siÄ™ image1.jpg, plik etykiety bÄ™dzie nazywaÅ‚ siÄ™ image1.txt.
* ZawartoÅ›Ä‡ pliku etykiety: KaÅ¼da linia w pliku etykiety reprezentuje jedno wykrycie obiektu na obrazie. Linia skÅ‚ada siÄ™ z nastÄ™pujÄ…cych elementÃ³w:
* Klasa obiektu: Liczba caÅ‚kowita reprezentujÄ…ca klasÄ™ obiektu (indeks w sÅ‚owniku klas). Na przykÅ‚ad, jeÅ›li masz 10 klas, klasy bÄ™dÄ… reprezentowane przez liczby od 0 do 9.
* x_center: WspÃ³Å‚rzÄ™dna Å›rodkowa obiektu na obrazie, wyraÅ¼ona jako procent szerokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).
* y_center: WspÃ³Å‚rzÄ™dna Å›rodkowa obiektu na obrazie, wyraÅ¼ona jako procent wysokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).
* width: SzerokoÅ›Ä‡ obiektu, wyraÅ¼ona jako procent szerokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).
* height: WysokoÅ›Ä‡ obiektu, wyraÅ¼ona jako procent wysokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).

**[0 0.437198 0.563786 0.826087 0.460905] = [klasa obiektu x_center, y_center width height]**
Etykietowanie naleÅ¼y wykonaÄ‡ dla np. 20 obrazÃ³w.

### Tworzenie pliku .yaml

:point_right: Plik .yaml w YOLO jest uÅ¼ywany do okreÅ›lenia Å›cieÅ¼ek do danych (obrazÃ³w i etykiet) oraz liczby klas obiektÃ³w. Jest to podstawowy element, ktÃ³ry pozwala na skonfigurowanie zbioru danych do trenowania modelu.

Plik konfiguracyjny do YOLO
```
train: ./images/train  # ÅšcieÅ¼ka do folderu z obrazami treningowymi
val: ./images/val      # ÅšcieÅ¼ka do folderu z obrazami walidacyjnymi
```
Lista nazw klas w zbiorze danych
```
names:
  0: person
  1: bicycle
  2: car
  3: motorcycle
  4: airplane
  5: bus
  6: train
  7: truck
  8: boat
  9: traffic light
  10: fire hydrant
  # MoÅ¼esz dodaÄ‡ wiÄ™cej klas w zaleÅ¼noÅ›ci od zbioru danych
```
```nc: 11  # Liczba klas obiektÃ³w (np. 11 klas)```

**:point_right: Kluczowe elementy pliku .yaml:**
* **train**: ÅšcieÅ¼ka do folderu z obrazami treningowymi. Zwykle obrazy sÄ… przechowywane w folderze images/train/.

* **val**: ÅšcieÅ¼ka do folderu z obrazami walidacyjnymi. Obrazy walidacyjne sÄ… przechowywane w folderze images/val/.

* **names**: Lista klas, gdzie kaÅ¼da klasa ma przypisanÄ… nazwÄ™. To jest lista obiektÃ³w, ktÃ³re model bÄ™dzie prÃ³bowaÅ‚ wykrywaÄ‡ (np. osoba, rower, samochÃ³d, itp.). Indeksy klas zaczynajÄ… siÄ™ od 0.

* **nc**: Liczba klas w zbiorze danych (np. 11 klas, jeÅ›li chcesz wykrywaÄ‡ 11 rÃ³Å¼nych obiektÃ³w).

Tworzenie pliku .yaml na podstawie etykiet i obrazÃ³w?
Aby stworzyÄ‡ plik .yaml na podstawie etykiet i obrazÃ³w w YOLO, musisz wykonaÄ‡ nastÄ™pujÄ…ce kroki:

* Zbierz obrazy: Upewnij siÄ™, Å¼e masz obrazy w odpowiednich folderach. Zazwyczaj struktura katalogÃ³w wyglÄ…da nastÄ™pujÄ…co:

ğŸ“ datasheet
- ğŸ“ images
  - ğŸ“ train
    - ğŸ–¼ï¸ img1.jpg
    - ğŸ–¼ï¸ img2.jpg
  - ğŸ“ val
    - ğŸ–¼ï¸ img3.jpg
    - ğŸ–¼ï¸ img4.jpg
- ğŸ“ labels
  - ğŸ“ train
    - ğŸ“ img1.txt
    - ğŸ“ img2.txt
  - ğŸ“ val
     - ğŸ“ img3.txt
     - ğŸ“ img4.txt

* W folderze **images/train/** znajdujÄ… siÄ™ obrazy do trenowania,
* W folderze **labels/train/** znajdujÄ… siÄ™ pliki tekstowe z etykietami w formacie YOLO (np. image1.txt, image2.txt, itd.). Folder images/val/ i labels/val/ zawierajÄ… obrazy i etykiety do walidacji.

Przygotuj plik z nazwami klas: TwÃ³j plik data.yaml bÄ™dzie musiaÅ‚ zawieraÄ‡ listÄ™ nazw klas w polu names. JeÅ›li masz klasy zapisane w plikach etykiet (np. obiekty w pliku image1.txt), zapisz nazwy klas, ktÃ³re chcesz wykrywaÄ‡, w pliku YAML w sekcji names. <br> 
PrzykÅ‚ad:

names: <br>
  0: person <br>
  1: bicycle <br>
  2: car <br>
  3: motorcycle <br>
  4: airplane <br>

**WskazÃ³wka:** Indeksy klas muszÄ… odpowiadaÄ‡ numerom w etykietach YOLO, czyli klasie 0 odpowiada person, klasie 1 bicycle, itd.
UtwÃ³rz plik .yaml: OtwÃ³rz dowolny edytor tekstu (np. Visual Studio Code, Notepad++) i stwÃ³rz plik data.yaml z odpowiedniÄ… zawartoÅ›ciÄ….

PrzykÅ‚ad pliku data.yaml:

train: /Å›cieÅ¼ka/do/folderu/images/train  # ZastÄ…p Å›cieÅ¼kÄ… do folderu z obrazami treningowymi
val: /Å›cieÅ¼ka/do/folderu/images/val    # ZastÄ…p Å›cieÅ¼kÄ… do folderu z obrazami walidacyjnymi

nc: 5  # Liczba klas (np. jeÅ›li masz 5 klas)
names:
  0: person
  1: bicycle
  2: car
  3: motorcycle
  4: airplane

Uwagi:

* train i val muszÄ… wskazywaÄ‡ na foldery, w ktÃ³rych znajdujÄ… siÄ™ obrazy treningowe i walidacyjne.

* nc to liczba klas w Twoim zbiorze danych (liczba nazw w sekcji names).

* names to lista klas, ktÃ³re chcesz wykrywaÄ‡ (liczby w tej liÅ›cie muszÄ… odpowiadaÄ‡ indeksom klas w etykietach YOLO).

* Zapisz plik: Zapisz plik jako data.yaml w odpowiednim miejscu w Twoim projekcie (np. w folderze z Twoimi danymi lub w folderze yolo/).

KoÅ„cowa struktura powinna wyglÄ…daÄ‡ tak: 

ğŸ“ project_1
  - ğŸ“„ data.yaml
- ğŸ“ images
  - ğŸ“ train
    - ğŸ–¼ï¸ img1.jpg
    - ğŸ–¼ï¸ img2.jpg
  - ğŸ“ val
    - ğŸ–¼ï¸ img3.jpg
    - ğŸ–¼ï¸ img4.jpg
- ğŸ“ labels
  - ğŸ“ train
    - ğŸ“ img1.txt
    - ğŸ“ img2.txt
  - ğŸ“ val
     - ğŸ“ img3.txt
     - ğŸ“ img4.txt

## :three: Fine-tuning modelu
:point_right: **Fine-tuning - proces dalszego treningu modelu, aby poprawiÄ‡ jego wyniki na okreÅ›lonym zbiorze danych, zwÅ‚aszcza jeÅ›li model zostaÅ‚ juÅ¼ wczeÅ›niej wytrenowany na duÅ¼ym zbiorze ogÃ³lnych danych.**
W Ä‡wiczeniu skorzystamy z automatycznego doboru parametrÃ³w dla uczenia maszynowego oferowanego przez funkcjÄ™ `model.tune()`

* Funkcja model.tune() w YOLO (i innych modelach w ultralytics) sÅ‚uÅ¼y do automatycznego dopasowywania hiperparametrÃ³w modelu do danych. WartoÅ›ci, ktÃ³re przekazujesz do tej funkcji, majÄ… duÅ¼y wpÅ‚yw na wydajnoÅ›Ä‡ modelu, czas treningu i jakoÅ›Ä‡ wynikÃ³w. Oto szczegÃ³Å‚owy opis, jak dobraÄ‡ parametry w tej funkcji:
***Parametry funkcji model.tune():***
`data` (data.yaml):
Opis: ÅšcieÅ¼ka do pliku .yaml, ktÃ³ry zawiera informacje o Twoim zbiorze danych, takie jak Å›cieÅ¼ki do folderÃ³w z obrazami treningowymi i walidacyjnymi oraz lista klas obiektÃ³w.

DobÃ³r: Ten parametr jest obowiÄ…zkowy. Plik YAML zawiera wszystkie informacje o danych, ktÃ³re sÄ… niezbÄ™dne do trenowania modelu. Upewnij siÄ™, Å¼e plik data.yaml jest poprawnie skonfigurowany, zawiera odpowiednie Å›cieÅ¼ki do danych i listÄ™ klas.

`epochs (epochs=4)`:

Opis: Liczba epok, czyli liczba peÅ‚nych przejÅ›Ä‡ przez zbiÃ³r treningowy.

DobÃ³r: Liczba epok zaleÅ¼y od wielkoÅ›ci Twojego zbioru danych i zÅ‚oÅ¼onoÅ›ci modelu. Na poczÄ…tek moÅ¼esz zaczÄ…Ä‡ od 10â€“50 epok. JeÅ›li model nie osiÄ…ga dobrych wynikÃ³w, moÅ¼esz zwiÄ™kszyÄ‡ liczbÄ™ epok. Zbyt duÅ¼a liczba epok moÅ¼e prowadziÄ‡ do przeuczenia modelu, dlatego waÅ¼ne jest monitorowanie wynikÃ³w na zbiorze walidacyjnym.

Zalecenie: JeÅ›li masz maÅ‚y zbiÃ³r danych, zacznij od 10-20 epok, a jeÅ›li masz duÅ¼y, zacznij od 50â€“100 epok i monitoruj postÄ™p.

`iterations (iterations=1):`

Opis: Liczba iteracji, ktÃ³re pozwalajÄ… na znalezienie optymalnych hiperparametrÃ³w.

DobÃ³r: WartoÅ›Ä‡ ta jest uÅ¼ywana w przypadku automatycznego dostosowywania hiperparametrÃ³w. DomyÅ›lnie jest ustawiona na 1, co oznacza, Å¼e model nie bÄ™dzie wykonywaÅ‚ optymalizacji hiperparametrÃ³w. JeÅ›li chcesz, aby model zoptymalizowaÅ‚ swoje hiperparametry, zwiÄ™ksz tÄ™ wartoÅ›Ä‡. Zbyt duÅ¼a liczba iteracji moÅ¼e jednak prowadziÄ‡ do wydÅ‚uÅ¼enia czasu treningu bez zauwaÅ¼alnej poprawy wynikÃ³w.

Zalecenie: JeÅ›li chcesz przeprowadziÄ‡ eksperymenty z optymalizacjÄ… hiperparametrÃ³w, uÅ¼yj wartoÅ›ci 2 lub 3 dla iterations. Jednak dla prostych zastosowaÅ„, wartoÅ›Ä‡ 1 moÅ¼e byÄ‡ wystarczajÄ…ca.

`imgsz (imgsz=640):`

Opis: Rozmiar obrazu, na ktÃ³rym model bÄ™dzie pracowaÄ‡. MoÅ¼e to byÄ‡ wartoÅ›Ä‡ w pikselach, np. 640x640 px.

DobÃ³r: WiÄ™kszy rozmiar obrazu pozwala na lepsze wykrywanie szczegÃ³Å‚Ã³w, ale takÅ¼e zwiÄ™ksza zapotrzebowanie na pamiÄ™Ä‡ GPU i wydÅ‚uÅ¼a czas obliczeÅ„. Typowo, dla YOLOv5 uÅ¼ywa siÄ™ rozmiarÃ³w 640x640 px lub 416x416 px. MoÅ¼esz sprÃ³bowaÄ‡ rÃ³Å¼nych rozmiarÃ³w w zaleÅ¼noÅ›ci od zasobÃ³w, jakie posiadasz.

Zalecenie: Rozpocznij od wartoÅ›ci 640, jeÅ›li masz wystarczajÄ…co duÅ¼o pamiÄ™ci GPU. W przypadku ograniczeÅ„ pamiÄ™ci, zmniejszenie rozmiaru do 416 moÅ¼e pomÃ³c.

`batch (batch=16):`

Opis: Rozmiar batcha, czyli liczba obrazÃ³w przetwarzanych rÃ³wnoczeÅ›nie w jednym kroku podczas treningu.

DobÃ³r: ZwiÄ™kszenie rozmiaru batcha moÅ¼e przyspieszyÄ‡ trening (szczegÃ³lnie na GPU), ale wymaga wiÄ™cej pamiÄ™ci. Optymalna wartoÅ›Ä‡ zaleÅ¼y od dostÄ™pnej pamiÄ™ci GPU. Standardowe wartoÅ›ci to 8, 16, 32.

Zalecenie: Zacznij od rozmiaru batcha 16. JeÅ›li TwÃ³j GPU ma ograniczonÄ… pamiÄ™Ä‡, sprÃ³buj z mniejszym rozmiarem batcha, np. 8.

`device (device=device):`

Opis: UrzÄ…dzenie, na ktÃ³rym ma odbywaÄ‡ siÄ™ trening. MoÅ¼esz wybraÄ‡ cpu lub cuda (jeÅ›li masz GPU).

DobÃ³r: JeÅ›li masz dostÄ™p do GPU, zawsze wybieraj cuda, poniewaÅ¼ pozwoli to znacznie przyspieszyÄ‡ trening. JeÅ›li nie masz GPU, uÅ¼ywaj cpu.

Zalecenie: UÅ¼ywaj cuda jeÅ›li masz kartÄ™ graficznÄ… kompatybilnÄ… z CUDA. Dla CPU uÅ¼yj cpu, chociaÅ¼ trening na CPU moÅ¼e byÄ‡ znacznie wolniejszy.

`workers (workers=8):`

Opis: Liczba wÄ…tkÃ³w do wczytywania danych.

DobÃ³r: OkreÅ›la, ile wÄ…tkÃ³w procesora zostanie uÅ¼ytych do rÃ³wnoczesnego Å‚adowania danych. WiÄ™ksza liczba wÄ…tkÃ³w moÅ¼e przyspieszyÄ‡ Å‚adowanie danych, ale zaleÅ¼y to od wydajnoÅ›ci Twojego CPU. JeÅ›li masz 8 rdzeni CPU, uÅ¼ycie wartoÅ›ci 8 lub 4 moÅ¼e byÄ‡ dobrym wyborem.

Zalecenie: Zaczynaj od wartoÅ›ci 8, a jeÅ›li zauwaÅ¼ysz problemy z wydajnoÅ›ciÄ… CPU, zmniejsz tÄ™ wartoÅ›Ä‡ (np. do 4).

`augment (augment=True):`

Opis: WÅ‚Ä…czenie augmentacji danych, czyli sztucznego zwiÄ™kszania rozmiaru zbioru danych poprzez rÃ³Å¼ne transformacje obrazÃ³w (np. obrÃ³t, przyciÄ™cie, zmiany jasnoÅ›ci, kontrastu, itp.).

DobÃ³r: Augmentacja pomaga zwiÄ™kszyÄ‡ rÃ³Å¼norodnoÅ›Ä‡ danych treningowych i moÅ¼e poprawiÄ‡ wyniki modelu, zwÅ‚aszcza gdy masz maÅ‚y zbiÃ³r danych. W wiÄ™kszoÅ›ci przypadkÃ³w warto jÄ… wÅ‚Ä…czyÄ‡, ale moÅ¼e zwiÄ™kszyÄ‡ czas treningu.

Zalecenie: UÅ¼ywaj augment=True, chyba Å¼e masz bardzo duÅ¼Ä… iloÅ›Ä‡ danych, w ktÃ³rym to przypadku augmentacja moÅ¼e nie byÄ‡ konieczna.

`project (project='...results/xyz'):`

Opis: Folder, w ktÃ³rym bÄ™dÄ… zapisywane wyniki treningu, w tym wykresy, model, logi itd.

DobÃ³r: Musisz okreÅ›liÄ‡ folder, w ktÃ³rym chcesz przechowywaÄ‡ wyniki. MoÅ¼esz podaÄ‡ Å›cieÅ¼kÄ™ do dowolnego katalogu na swoim dysku.

Zalecenie: UÅ¼yj unikalnej Å›cieÅ¼ki dla kaÅ¼dego eksperymentu, aby Å‚atwo rozrÃ³Å¼niaÄ‡ wyniki rÃ³Å¼nych sesji treningowych.

`name (name='lab3_a'):`

Opis: Nazwa eksperymentu, ktÃ³ra bÄ™dzie uÅ¼ywana do oznaczenia folderu wynikÃ³w.

DobÃ³r: MoÅ¼e to byÄ‡ dowolna nazwa, np. nazwa eksperymentu, data, itp.

Zalecenie: UÅ¼ywaj nazw, ktÃ³re pomagajÄ… Ci Å‚atwo zidentyfikowaÄ‡ dany eksperyment. Na przykÅ‚ad, jeÅ›li trenujesz model na detekcji rÃ³Å¼nych obiektÃ³w, uÅ¼yj nazwy zwiÄ…zanej z tym zadaniem, np. figury_UNITY.

### :star: Podsumowanie:

* Liczba epok: ZwiÄ™kszaj, jeÅ›li model nie konwerguje po kilku epokach.

* Iterations: Ustaw na 1, chyba Å¼e eksperymentujesz z automatycznym dostosowywaniem hiperparametrÃ³w.

* Rozmiar obrazu: Standardowo 640, ale moÅ¼esz zmniejszyÄ‡, jeÅ›li masz ograniczonÄ… pamiÄ™Ä‡ GPU.

* Rozmiar batcha: Zaczynaj od 16, ale dostosuj do dostÄ™pnej pamiÄ™ci.

* Device: UÅ¼ywaj cuda dla GPU, cpu dla CPU.

* Workers: ZwiÄ™kszaj, jeÅ›li masz wydajny CPU.

* Augmentacja: Zalecana, zwÅ‚aszcza przy maÅ‚ych zbiorach danych.

**KaÅ¼dy z tych parametrÃ³w ma wpÅ‚yw na czas treningu oraz jakoÅ›Ä‡ wynikÃ³w. Warto testowaÄ‡ rÃ³Å¼ne kombinacje, aby znaleÅºÄ‡ najlepszÄ… dla swojego przypadku.**

* **przykÅ‚adowy skrypt `train_own_model.py`**

```python
if __name__ == '__main__':
    from ultralytics import YOLO
    import torch
    import time
    model_path = r'yolov5su.pt'
    model = YOLO(model_path)

    # Automatyczne wykrywanie GPU
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    model.to(device)
    start = time.time()
    # # Tuning hiperparametrÃ³w - Automatyczne dostosowywanie
    model.tune(
        data='data.yaml',   # Plik konfiguracyjny danych
        epochs=4,          # Liczba epok 50
        iterations=1,      # Liczba iteracji, ktÃ³re pozwalajÄ… na znalezienie optymalnych hiperparametrÃ³w 2
        imgsz=640,          # Rozmiar obrazu
        batch=16,            # Rozmiar batcha
        device=device,      # WybÃ³r urzÄ…dzenia (GPU/CPU)
        workers=8,          # Liczba wÄ…tkÃ³w do wczytywania danych
        augment=True,       # Augmentacja
        project='../results/xyz', # Folder zapisu wynikÃ³w
        name='exp_1'    # Nazwa eksperymentu
    )

```
Po uruchomieniu kodu z funkcjÄ… model.tune(), zakÅ‚adajÄ…c, Å¼e dane sÄ… poprawnie przygotowane (tzn. obrazy oraz etykiety w odpowiednich formatach i pliku data.yaml sÄ… dobrze skonfigurowane), wynik dziaÅ‚ania tego kodu powinien obejmowaÄ‡:

* **1. Trening modelu YOLOv5:**
Model zostanie wytrenowany przy uÅ¼yciu dostarczonych danych treningowych (obrazÃ³w i etykiet).

* Automatyczne dostosowywanie hiperparametrÃ³w: Funkcja `model.tune()` bÄ™dzie prÃ³bowaÅ‚a optymalizowaÄ‡ hiperparametry 
modelu (np. rozmiar batcha, liczba epok, augmentacja) w ramach podanych iteracji. JeÅ›li nie ustawisz wartoÅ›ci wiÄ™kszej niÅ¼ 1 dla 
`iterations`, to hiperparametry nie bÄ™dÄ… dostosowywane, a trening bÄ™dzie wykonywany z domyÅ›lnymi ustawieniami.

* Rozpocznie trening modelu z okreÅ›lonÄ… liczbÄ… epok (np. 4) oraz przy innych zadanych parametrach.

* Wykorzystanie GPU/CPU: W zaleÅ¼noÅ›ci od tego, czy masz dostÄ™p do GPU, model zostanie uruchomiony na odpowiednim urzÄ…dzeniu (cuda lub cpu).

* **2. Monitoring procesu treningu:**
* Wydruk wynikÃ³w: Podczas treningu bÄ™dÄ… wyÅ›wietlane informacje o postÄ™pie, takie jak:
  * Strata (`loss`) na zbiorze treningowym oraz walidacyjnym.
  * Czas treningu.
  * WartoÅ›ci metryk (np. `mAP - mean Average Precision`) dla wykrywania obiektÃ³w.

PrzykÅ‚ad konsoli:

```bash 
Epoch [1/4] | Training loss: 0.34 | Validation loss: 0.28 | mAP@0.5: 0.85 | mAP@0.75: 0.72
Epoch [2/4] | Training loss: 0.30 | Validation loss: 0.26 | mAP@0.5: 0.87 | mAP@0.75: 0.74
Epoch [3/4] | Training loss: 0.27 | Validation loss: 0.25 | mAP@0.5: 0.88 | mAP@0.75: 0.75
Epoch [4/4] | Training loss: 0.24 | Validation loss: 0.22 | mAP@0.5: 0.90 | mAP@0.75: 0.78
```
* Strata (`Loss`): Z kaÅ¼dym krokiem treningu bÄ™dzie wyÅ›wietlana wartoÅ›Ä‡ straty, zarÃ³wno na zbiorze treningowym, jak i walidacyjnym. Strata powinna maleÄ‡, co oznacza, Å¼e model siÄ™ "uczy".

* Wyniki `mAP` (mean Average Precision): Podczas treningu i po zakoÅ„czeniu kaÅ¼dej epoki bÄ™dzie podawana wartoÅ›Ä‡ mAP na zbiorze walidacyjnym (im wyÅ¼sza wartoÅ›Ä‡, tym lepszy model).

* **3. Wyniki zapisywane do folderu wynikÃ³w:** 
  * Po zakoÅ„czeniu treningu, wszystkie wyniki zostanÄ… zapisane w folderze okreÅ›lonym w parametrze project, w tym:
    * Modele (np. best.pt, last.pt) zapisane w folderze runs/train/exp/weights/.
      * Logi z treningu zapisane w plikach .txt w folderze runs/train/exp/. 
      * Wykresy (np. wykresy straty i metryk) zapisane w folderze runs/train/exp/plots/.

**struktura folderu wynikÃ³w:** 
* :open_file_folder: results
  * :open_file_folder: results/xyz
    * :open_file_folder: runs
      * :open_file_folder:exp_1
        * :file_folder: weights
          * :large_blue_diamond: best.py
          * :large_blue_diamond: last.pt
        * :file_folder: logs
          * ğŸ“„ train.txt
        * :file_folder: plots
          * ğŸ–¼ï¸ loss.png
          * ğŸ–¼ï¸ metrics.png
 

* **4. Wynik w oknie graficznym:**
`results.show()`: JeÅ›li ten parametr jest aktywowany, wyniki bÄ™dÄ… takÅ¼e wyÅ›wietlane w oknie graficznym. BÄ™dziesz mÃ³gÅ‚ zobaczyÄ‡ obrazy z detekcjami obiektÃ³w na przykÅ‚adzie kilku obrazÃ³w z zbioru walidacyjnego.

PrzykÅ‚ad: Na obrazach zostanÄ… narysowane prostokÄ…ty wokÃ³Å‚ wykrytych obiektÃ³w, a takÅ¼e zostanÄ… wyÅ›wietlone ich klasy i prawdopodobieÅ„stwa detekcji.

* **5. Czas treningu:**
Zmienna start rejestruje czas rozpoczÄ™cia treningu, a po zakoÅ„czeniu procesu wyÅ›wietli czas trwania treningu.

**PrzykÅ‚ad:**

* Czas treningu: 240.123 sekundy
**Potencjalne problemy:**
  * BrakujÄ…ce dane: JeÅ›li foldery z obrazami lub etykietami sÄ… nieprawidÅ‚owe lub puste, lub jeÅ›li dane w plikach .txt sÄ… Åºle sformatowane (np. zÅ‚e klasy lub niepoprawne wspÃ³Å‚rzÄ™dne prostokÄ…tÃ³w), model moÅ¼e zakoÅ„czyÄ‡ trening z bÅ‚Ä™dami lub nie osiÄ…gnÄ…Ä‡ dobrych wynikÃ³w.

  * BÅ‚Ä™dy w pliku data.yaml: JeÅ›li plik data.yaml jest Åºle skonfigurowany (np. niepoprawne Å›cieÅ¼ki do folderÃ³w, brak klas), trening moÅ¼e zakoÅ„czyÄ‡ siÄ™ niepowodzeniem.

  * Zbyt maÅ‚a liczba epok: JeÅ›li liczba epok jest zbyt maÅ‚a (np. 4 epoki), model moÅ¼e nie mieÄ‡ wystarczajÄ…co czasu na naukÄ™, co prowadzi do sÅ‚abych wynikÃ³w.

**:bulb:  Podsumowanie:** 
* Po poprawnym uruchomieniu kodu, wynik bÄ™dzie obejmowaÄ‡:
  * Wyniki treningu i walidacji na kaÅ¼dej epoce (strata, mAP, itp.). 
  * Modele zapisane w folderze wynikÃ³w (best.pt, last.pt).

* Wykresy i logi procesu treningu. 
  * Czas trwania treningu.
  *(Opcjonalnie) Obrazy z detekcjami wyÅ›wietlane w oknie graficznym.

**Wyniki treningu bÄ™dÄ… zaleÅ¼ne od jakoÅ›ci danych (obrazÃ³w i etykiet), liczby epok oraz innych hiperparametrÃ³w, ktÃ³re ustawiÅ‚eÅ›.** 

### Sprawdzenie dokÅ‚adnoÅ›ci modelu

Ostatni krok to sprawdzenie dokÅ‚adnoÅ›ci modelu:
```python
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
path = r"C:\...\weights\best.pt"
model = YOLO(path)
img_path = r"example_image"
img = cv2.imread(img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Konwersja do RGB dla poprawnego wyÅ›wietlania
results = model(img_path)
annotated_img = results[0].plot()  # Narysuj wykryte obiekty na obrazie
plt.imshow(annotated_img)
plt.axis('off')
plt.show()
```

### WyjaÅ›nienie: 

`YOLO` z `ultralytics` - Importuje klasÄ™ do uÅ¼ywania modeli YOLOv5.

`cv2 (OpenCV)` - UÅ¼ywane do wczytywania i przetwarzania obrazÃ³w.

`matplotlib.pyplot` - UÅ¼ywane do wyÅ›wietlania obrazÃ³w z detekcjami w oknie graficznym.

`model` - Wczytuje zapisany model YOLOv5 z pliku .pt, ktÃ³ry znajduje siÄ™ w Å›cieÅ¼ce okreÅ›lonej przez zmiennÄ… path. Ten plik zawiera wagi wytrenowanego modelu. Model ten bÄ™dzie wykorzystywany do detekcji obiektÃ³w na obrazie.

`cv2.imread` - Wczytuje obraz z dysku za pomocÄ… OpenCV (funkcja cv2.imread). ÅšcieÅ¼ka do obrazu jest okreÅ›lona przez zmiennÄ… img_path. Obraz jest Å‚adowany w formacie BGR, co jest standardem w OpenCV.

`cv2.cvtColor(img, cv2.COLOR_BGR2RGB)` - OpenCV domyÅ›lnie uÅ¼ywa formatu BGR, ale dla poprawnego wyÅ›wietlania w matplotlib, obraz musi byÄ‡ w formacie RGB. Ta linia kodu konwertuje obraz z BGR na RGB.

`results` - Przekazuje obraz do modelu YOLOv5, aby przeprowadziÄ‡ detekcjÄ™ obiektÃ³w.

Wyniki sÄ… zapisane w obiekcie `results`, ktÃ³ry zawiera wykryte obiekty, w tym ich wspÃ³Å‚rzÄ™dne i klasy.

`annotated_img` = Ta linia rysuje prostokÄ…ty wokÃ³Å‚ wykrytych obiektÃ³w na obrazie. Funkcja `plot()` automatycznie dodaje adnotacje, takie jak klasy wykrytych obiektÃ³w i ich prawdopodobieÅ„stwa, na oryginalnym obrazie. 
`results[0]` odnosi siÄ™ do pierwszego (i czÄ™sto jedynego) obrazu w wynikach, poniewaÅ¼ funkcja detekcji jest uruchamiana na jednym obrazie.
`plt.imshow(annotated_img)` - WyÅ›wietla obraz z wykrytymi obiektami.

`plt.axis('off')` - Ukrywa osie wykresu (aby obraz byÅ‚ wyÅ›wietlany bez zbÄ™dnych oznaczeÅ„ osi).

`plt.show()` - Pokazuje okno z obrazem.

* Co otrzymasz w wyniku dziaÅ‚ania tego kodu:
  * Na obrazie bÄ™dÄ… narysowane prostokÄ…ty wokÃ³Å‚ wykrytych obiektÃ³w, a takÅ¼e ich etykiety oraz prawdopodobieÅ„stwa detekcji. 
  * Obraz zostanie wyÅ›wietlony w oknie graficznym (dziÄ™ki `matplotlib`), co pozwala na wizualnÄ… weryfikacjÄ™ wynikÃ³w detekcji.


# Praca z danymi wirtualnymi
