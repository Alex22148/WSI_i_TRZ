# Podstawy uczenia maszynowego

## :one: Skorzystanie z gotowego modelu 

W Ä‡wiczeniu zostanie przedstawione podstawowe dziaÅ‚anie modelu YOLO5.
w skrypcie `YOLO5_classes.py` znajdujÄ… siÄ™ obsÅ‚ugiwane przez model klasy obiektÃ³w. 
ObsÅ‚ugiwane klasy to np.:

```python 
names = {
  0: "person",
  1: "bicycle",
  2: "car",
  3: "motorcycle",
  4: "airplane",
  5: "bus",
  6: "train"
}
```

### Testowanie modelu na swoich danych
W skrypcie ```usage_custom_model.py``` znajduje siÄ™ podstawowy skrypt do wizualizacji wynikÃ³w
uzyskanych przez analizÄ™ obrazu uÅ¼ywajÄ…c model YOLO5. Przy pierwszym uÅ¼yciu model
naleÅ¼y pobraÄ‡ z oficjalnego repozytorium https://github.com/ultralytics/yolov5

### **skrypt `usage_custom_model.py`**
```python
import torch
model = torch.hub.load("ultralytics/yolov5", "yolov5s")  # Default: yolov5s
img = "example_image.jpg" # lub https://ultralytics.com/images/zidane.jpg"
results = model(img)
results.print()
results.show()
results.save() 
```
* `torch` Importuje bibliotekÄ™ PyTorch, ktÃ³ra jest podstawowÄ… bibliotekÄ… do pracy z sieciami neuronowymi w Pythonie. W tym przypadku jest wykorzystywana do zaÅ‚adowania modelu YOLOv5.
* `torch.hub.load()`: Funkcja ta pozwala na zaÅ‚adowanie modelu z repozytorium GitHub. W tym przypadku Å›ciÄ…gamy model YOLOv5 bezpoÅ›rednio z repozytorium ultralytics/yolov5. UÅ¼ywajÄ…c torch.hub, moÅ¼emy szybko zaÅ‚adowaÄ‡ model bez koniecznoÅ›ci pobierania go lokalnie.
* `"ultralytics/yolov5"`: To repozytorium GitHub, z ktÃ³rego jest Å‚adowany model YOLOv5.
* `"yolov5s"`: Jest to wersja modelu YOLOv5, ktÃ³rej chcemy uÅ¼yÄ‡. YOLOv5 ma rÃ³Å¼ne wersje: yolov5n (najmniejsza), yolov5s (small), yolov5m (medium), yolov5l (large), yolov5x (extra-large). Model yolov5s jest najczÄ™Å›ciej uÅ¼ywany, poniewaÅ¼ zapewnia dobry kompromis miÄ™dzy szybkoÅ›ciÄ… a dokÅ‚adnoÅ›ciÄ….
* `img`: Zmienna przechowuje adres URL do obrazu, ktÃ³ry bÄ™dzie uÅ¼yty do wykrywania obiektÃ³w. W tym przypadku jest to przykÅ‚adowy obraz Zidane udostÄ™pniony przez twÃ³rcÃ³w YOLOv5. MoÅ¼esz zastÄ…piÄ‡ ten URL lokalnym plikiem obrazka, podajÄ…c odpowiedniÄ… Å›cieÅ¼kÄ™ do pliku w swoim systemie.
* `model(img)` :Przekazuje obraz do modelu, aby wykonaÄ‡ detekcjÄ™ obiektÃ³w. Model YOLOv5 analizuje obraz, identyfikuje obiekty (np. osoby, samochody, zwierzÄ™ta) i zwraca wyniki w postaci obiektÃ³w zawierajÄ…cych informacje o wykrytych obiektach (np. wspÃ³Å‚rzÄ™dne bounding boxÃ³w, klasy obiektÃ³w, poziom pewnoÅ›ci).
* `results.print()`: WyÅ›wietla wyniki detekcji obiektÃ³w w konsoli. Na przykÅ‚ad, dla kaÅ¼dego wykrytego obiektu pokazuje:
* `results.save()`: Zapisuje wyniki detekcji do folderu na dysku. DomyÅ›lnie wyniki zostanÄ… zapisane w katalogu runs/detect/exp w folderze roboczym. W folderze tym znajdziesz obrazy z naniesionymi wynikami detekcji, a takÅ¼e pliki tekstowe zawierajÄ…ce szczegÃ³Å‚y dotyczÄ…ce wykrytych obiektÃ³w.

:file_folder: PrzykÅ‚ad struktury wynikÃ³w:

Po uruchomieniu kodu, w folderze runs/detect/exp mogÄ… pojawiÄ‡ siÄ™ nastÄ™pujÄ…ce pliki:

`example_image.jpg`: Obraz wejÅ›ciowy z naniesionymi ramkami wokÃ³Å‚ wykrytych obiektÃ³w.

`labels`: Plik z tekstowym opisem wykrytych obiektÃ³w (wspÃ³Å‚rzÄ™dne ramki, klasy, pewnoÅ›Ä‡).

### :bulb: Podsumowanie:
:heavy_check_mark: ZaÅ‚adowanie modelu YOLOv5: Model YOLOv5 jest Å‚adowany za pomocÄ… `torch.hub.load()` z repozytorium GitHub.

:heavy_check_mark: Przekazanie obrazu do modelu: Obraz jest analizowany przez model w celu detekcji obiektÃ³w.

:heavy_check_mark: WyÅ›wietlenie wynikÃ³w: MoÅ¼na wyÅ›wietliÄ‡ wyniki na konsoli oraz na obrazie.

:heavy_check_mark: Zapisanie wynikÃ³w: Wyniki detekcji sÄ… zapisywane w folderze roboczym.

:heavy_check_mark: Ten kod pozwala na Å‚atwe uruchomienie detekcji obiektÃ³w za pomocÄ… YOLOv5 w jednym kroku, bez koniecznoÅ›ci lokalnej instalacji i konfiguracji modelu.

---

## :two: Tworzenie dodatkowych zbiorÃ³w danych

Aby przeprowadziÄ‡ fine-tuning (dostrajanie) modelu, niezbÄ™dne jest przygotowanie dodatkowego zbioru danych, ktÃ³ry zawiera zarÃ³wno obrazy, jak i odpowiadajÄ…ce im etykiety. OprÃ³cz samych danych konieczne jest takÅ¼e utworzenie pliku konfiguracyjnego w formacie .yaml, ktÃ³ry okreÅ›la podstawowe informacje o zbiorze danych, takie jak Å›cieÅ¼ki do folderÃ³w z obrazami, liczba klas oraz ich nazwy.

Warto zaznaczyÄ‡, Å¼e kaÅ¼dy model moÅ¼e wymagaÄ‡ nieco innej struktury organizacji danych i formatu etykiet. Dla modeli opartych na YOLO (You Only Look Once), obowiÄ…zuje specyficzna konwencja zapisu, ktÃ³ra wyglÄ…da nastÄ™pujÄ…co:

### **Struktura pliku etykiety YOLO:**
przykÅ‚adowa zawartoÅ›Ä‡ wygenerowanego pliku: <br>
**0 0.437198 0.563786 0.826087 0.460905** <br>
* Nazwa pliku etykiety: KaÅ¼dy plik z etykietÄ… ma takÄ… samÄ… nazwÄ™ jak obraz, z tÄ… rÃ³Å¼nicÄ…, Å¼e zamiast rozszerzenia .jpg, .png lub innego rozszerzenia obrazu, uÅ¼ywa rozszerzenia .txt. Na przykÅ‚ad, jeÅ›li obraz nazywa siÄ™ image1.jpg, plik etykiety bÄ™dzie nazywaÅ‚ siÄ™ image1.txt.
* ZawartoÅ›Ä‡ pliku etykiety: KaÅ¼da linia w pliku etykiety reprezentuje jedno wykrycie obiektu na obrazie. Linia skÅ‚ada siÄ™ z nastÄ™pujÄ…cych elementÃ³w:
* Klasa obiektu: Liczba caÅ‚kowita reprezentujÄ…ca klasÄ™ obiektu (indeks w sÅ‚owniku klas). Na przykÅ‚ad, jeÅ›li masz 10 klas, klasy bÄ™dÄ… reprezentowane przez liczby od 0 do 9.
* x_center: WspÃ³Å‚rzÄ™dna Å›rodkowa obiektu na obrazie, wyraÅ¼ona jako procent szerokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).
* y_center: WspÃ³Å‚rzÄ™dna Å›rodkowa obiektu na obrazie, wyraÅ¼ona jako procent wysokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).
* width: SzerokoÅ›Ä‡ obiektu, wyraÅ¼ona jako procent szerokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).
* height: WysokoÅ›Ä‡ obiektu, wyraÅ¼ona jako procent wysokoÅ›ci obrazu (wartoÅ›Ä‡ z przedziaÅ‚u 0.0â€“1.0).

**[0 0.437198 0.563786 0.826087 0.460905] = [klasa obiektu x_center, y_center width height]**

### **Dodatkowy zbiÃ³r danych obrazowych - dodanie nowej etykiety** <br>
Do wstÄ™pnie wytrenowanego modelu moÅ¼na dodaÄ‡ dowolnÄ… nowÄ… klasÄ™ (etykietÄ™), rozszerzajÄ…c jego moÅ¼liwoÅ›ci rozpoznawania. Warunkiem takiego procesu jest posiadanie odpowiedniego, dodatkowego zbioru danych zawierajÄ…cego obrazy oraz odpowiadajÄ…ce im etykiety dla nowej klasy.

W ramach Ä‡wiczenia taki zbiÃ³r zostaÅ‚ pobrany z platformy Kaggle, ktÃ³ra oferuje szeroki wybÃ³r gotowych zestawÃ³w danych:
ğŸ”— https://www.kaggle.com/datasets

Dodatkowym zbiorem obrazÃ³w bÄ™dÄ… zdjÄ™cia butÃ³w o etykiecie ***sneakers***

**Etykietowanie obrazÃ³w - automatyczne**

W przypadku obrazÃ³w, na ktÃ³rych jedynym widocznym elementem jest but, etykiety mogÄ… byÄ‡ generowane automatycznie za pomocÄ… skryptu ```automat_labels.py``` 
Po jego uruchomieniu dla wybranego katalogu, zostanÄ… utworzone etykiety przypisane do kaÅ¼dego obrazu, w ktÃ³rych region zainteresowania (ROI) obejmuje caÅ‚y obraz, 
a etykieta obiektu przyjmuje wartoÅ›Ä‡ "0". DziÄ™ki temu nie ma potrzeby rÄ™cznego wskazywania wspÃ³Å‚rzÄ™dnych obiektu â€“ jak pokazano na poniÅ¼szym przykÅ‚adzie, zdjÄ™cie przedstawiajÄ…ce pojedynczy but nie wymaga dodatkowej lokalizacji obiektu, poniewaÅ¼ jest on jednoznacznie widoczny i obejmuje caÅ‚Ä… przestrzeÅ„ kadru.

:point_right:**Zalety i ograniczenia automatycznego etykietowania**
Automatyczne etykietowanie znacznie przyspiesza proces przygotowywania danych, zwÅ‚aszcza w sytuacjach, gdy obrazy sÄ… jednorodne i zawierajÄ… tylko jeden, Å‚atwo rozpoznawalny obiekt. DziÄ™ki temu moÅ¼na w krÃ³tkim czasie wygenerowaÄ‡ duÅ¼Ä… liczbÄ™ etykiet bez angaÅ¼owania czasu annotatorÃ³w. NaleÅ¼y jednak pamiÄ™taÄ‡, Å¼e metoda ta sprawdza siÄ™ wyÅ‚Ä…cznie w prostych przypadkach â€“ np. gdy obiekt w peÅ‚ni wypeÅ‚nia obraz i nie wystÄ™pujÄ… Å¼adne elementy tÅ‚a, ktÃ³re mogÅ‚yby zakÅ‚Ã³ciÄ‡ interpretacjÄ™. W bardziej zÅ‚oÅ¼onych scenach, zawierajÄ…cych wiele obiektÃ³w lub niejednoznaczne ukÅ‚ady, nadal konieczne jest rÄ™czne etykietowanie w celu zachowania wysokiej jakoÅ›ci danych uczÄ…cych.

<div align="center">
  <img src="Images\Sneaker-Train (208).jpeg" alt="Calib_table" title="" width="300">
</div>

---
**Etykietowanie obrazÃ³w - rÄ™czne** <br>
RÄ™czne etykietowanie, czyli wskazywanie interesujÄ…cego obiektu w scenie, jest wykonywane w sytuacjach, gdy nie moÅ¼na jednoznacznie zidentyfikowaÄ‡ obiektu na obrazie za pomocÄ… automatycznych metod. W takich przypadkach konieczne jest precyzyjne okreÅ›lenie lokalizacji obiektu przez czÅ‚owieka â€“ np. poprzez zaznaczenie obszaru, w ktÃ³rym siÄ™ znajduje â€“ tak, aby dane te mogÅ‚y zostaÄ‡ efektywnie wykorzystane do trenowania modelu uczÄ…cego siÄ™. Proces ten zwiÄ™ksza jakoÅ›Ä‡ i dokÅ‚adnoÅ›Ä‡ zbioru danych, umoÅ¼liwiajÄ…c lepsze rozpoznawanie i interpretacjÄ™ obiektÃ³w przez algorytmy sztucznej inteligencji.
Do etykietowania obrazÃ³w w Ä‡wiczeniu bÄ™dzie wykorzystywany skrypt ```labeling.py```. Jest to prosty skrypt do etykietowania danych zgodnie
z obowiÄ…zujÄ…cym formatem w modelach YOLO. 

* :point_right: **Zalety i ograniczenia rÄ™cznego etykietowania**

RÄ™czne etykietowanie, choÄ‡ czasochÅ‚onne, pozostaje niezastÄ…pione w przypadkach, gdy automatyczne metody zawodzÄ… â€“ np. w scenach zawierajÄ…cych wiele obiektÃ³w, elementy czÄ™Å›ciowo zasÅ‚oniÄ™te, trudne do rozrÃ³Å¼nienia tÅ‚o lub niejednoznaczne ukÅ‚ady. DziÄ™ki bezpoÅ›redniemu zaangaÅ¼owaniu czÅ‚owieka moÅ¼liwe jest bardzo precyzyjne oznaczenie lokalizacji i klasy obiektu, co znaczÄ…co podnosi jakoÅ›Ä‡ zbioru danych i wpÅ‚ywa na skutecznoÅ›Ä‡ trenowanych modeli.
Z drugiej strony, rÄ™czne etykietowanie jest procesem pracochÅ‚onnym i kosztownym, zwÅ‚aszcza w przypadku duÅ¼ych zbiorÃ³w danych. MoÅ¼e byÄ‡ rÃ³wnieÅ¼ podatne na subiektywnoÅ›Ä‡ i bÅ‚Ä™dy ludzkie, dlatego czÄ™sto wymaga weryfikacji i standaryzacji. Pomimo tych trudnoÅ›ci, w wielu zastosowaniach, szczegÃ³lnie tam, gdzie wymagana jest wysoka dokÅ‚adnoÅ›Ä‡, rÄ™czna adnotacja jest nieodzownym elementem przygotowania danych.

<div align="center">
  <img src="Images\Sneaker-Train (976).jpeg" alt="Calib_table" title="" width="300">
</div>


---

W projekcie zostaÅ‚ stworzony jeden folder gÅ‚Ã³wny z dwoma podkatalogami. 
* :file_folder: temp_folder
  * :file_folder: automat_labels
  * :file_folder: manual_labels

Skrypt automatycznie generuje etykiety YOLO dla obrazÃ³w, zakÅ‚adajÄ…c, Å¼e caÅ‚y obraz przedstawia pojedynczy obiekt klasy â€0â€, i zapisuje zarÃ³wno obrazy, jak i odpowiadajÄ…ce im etykiety do odpowiednich folderÃ³w.

```python
import os
import cv2
import shutil

# ÅšcieÅ¼ka do folderu wejÅ›ciowego (tam gdzie sÄ… obrazy)
base_dir = os.getcwd()
input_folder = base_dir + "\\" + r"temp_folder\automat_labels"
folders = os.listdir(input_folder)
for folder in folders:
    full_path = os.path.join(base_dir,input_folder, folder)
    output_image_folder = os.path.join(base_dir, r"datasheets\images", str(folder))
    output_label_folder = os.path.join(base_dir, r"datasheets\labels", str(folder))
    # Tworzymy foldery wyjÅ›ciowe, jeÅ›li nie istniejÄ…
    os.makedirs(output_image_folder, exist_ok=True)
    os.makedirs(output_label_folder, exist_ok=True)
    # Wspierane rozszerzenia
    valid_ext = ('.jpg', '.jpeg', '.png', '.bmp')
    filenames = os.listdir(full_path)
    print(filenames)
    for filename in filenames:
        if filename.lower().endswith(valid_ext):
            image_path = os.path.join(input_folder,folder, filename)
            print(image_path)
            img = cv2.imread(image_path)

            if img is None:
                print(f"âš ï¸ Nie moÅ¼na wczytaÄ‡: {filename}")
                continue

            h, w = img.shape[:2]

            # CaÅ‚y obraz traktowany jako obiekt klasy '0'
            x_center = 0.5
            y_center = 0.5
            width = 1.0
            height = 1.0

            yolo_line = f"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n"

            # Zapis do folderu labels
            label_name = os.path.splitext(filename)[0] + '.txt'
            label_path = os.path.join(output_label_folder, label_name)

            with open(label_path, 'w') as f:
                f.write(yolo_line)

            # Kopiowanie obrazu do folderu images
            shutil.copy(image_path, os.path.join(base_dir,output_image_folder, filename))

            print(f"âœ… Przetworzono: {filename}")

print("\nğŸ‰ Gotowe! YOLO-labelki wygenerowane.")


```
Opis funkcjonalnoÅ›ci kodu:

```import os, cv2, shutil``` â€“ biblioteki do obsÅ‚ugi plikÃ³w, obrazÃ³w oraz kopiowania.

```base_dir = os.getcwd()``` â€“ pobiera katalog, z ktÃ³rego uruchamiany jest skrypt (punkt odniesienia dla Å›cieÅ¼ek wzglÄ™dnych).

```input_folder = ...``` â€“ ustawia Å›cieÅ¼kÄ™ do katalogu z folderami zawierajÄ…cymi obrazy do przetworzenia.

```os.listdir(input_folder)``` â€“ zbiera listÄ™ podfolderÃ³w (np. rÃ³Å¼nych kategorii lub zestawÃ³w danych).

```PÄ™tla for folder in folders:``` â€“ iteruje przez kaÅ¼dy podfolder w katalogu automat_labels.

```os.makedirs(..., exist_ok=True)``` â€“ tworzy (jeÅ›li nie istniejÄ…) foldery na obrazy i etykiety osobno dla kaÅ¼dego zestawu.

```valid_ext``` â€“ lista dozwolonych rozszerzeÅ„ obrazÃ³w.

```cv2.imread()``` â€“ wczytuje obraz z pliku.

WspÃ³Å‚rzÄ™dne YOLO (```x_center, y_center, width, height```) â€“ zakÅ‚adajÄ…, Å¼e obiekt klasy 0 zajmuje caÅ‚y obraz.

Tworzenie pliku .txt â€“ nazwa etykiety jest taka sama jak nazwa obrazu, ale z rozszerzeniem .txt.

```shutil.copy()``` â€“ kopiuje oryginalny obraz do folderu docelowego (```datasheets/images/[folder]```).


* **RÄ™czne etykietowanie - skrypt**

Skrypt sÅ‚uÅ¼y do rÄ™cznego etykietowania obiektÃ³w na obrazach â€“ uÅ¼ytkownik zaznacza myszkÄ… prostokÄ…t wokÃ³Å‚ obiektu (np. buta), a program zapisuje te dane w formacie YOLO jako etykiety klasy â€sneakersâ€ oraz kopiuje odpowiadajÄ…ce obrazy i etykiety do odpowiednich folderÃ³w.


```python
import os
import cv2
import shutil
import sys

# Foldery gÅ‚Ã³wne
image_folder = r'image_folder'
det_folder = 'labels'

# Tworzenie struktury
for subfolder in ['images', 'labels']:
    os.makedirs(os.path.join(det_folder, subfolder), exist_ok=True)

# Mapowanie klas
class_map = {
    'sneakers': 0
}

def normalize_bbox(pt1, pt2, w, h):
    x_center = ((pt1[0] + pt2[0]) / 2) / w
    y_center = ((pt1[1] + pt2[1]) / 2) / h
    box_w = abs(pt2[0] - pt1[0]) / w
    box_h = abs(pt2[1] - pt1[1]) / h
    return x_center, y_center, box_w, box_h

images = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png', '.bmp', 'jpeg'))]

for img_name in images:
    img_path = os.path.join(image_folder, img_name)
    img = cv2.imread(img_path)
    h, w = img.shape[:2]

    objects = []
    current_points = []
    label_class = None
    draw_mode = None

    print(f"\nğŸ“· Obrazek: {img_name}")
    print("s = draw sneakers label | n = next | r = reset | q = confirm | ESC = quit")

    window = 'Label Tool'
    cv2.namedWindow(window)

    def draw(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            current_points.append((x, y))

    cv2.setMouseCallback(window, draw)

    while True:
        temp = img.copy()
        if len(current_points) == 2:
            cv2.rectangle(temp, current_points[0], current_points[1], (0, 255, 0), 2)

        cv2.putText(temp, f"{img_name}", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.imshow(window, temp)

        key = cv2.waitKey(1)

        if key == ord('s'):
            label_class = 'sneakers'
            current_points = []
            print("ğŸ¯ sneakers: rysuj prostokat (2 punkty), q = zatwierdz")

        elif key == ord('r'):
            print("ğŸ”„ Reset oznaczenia")
            current_points = []

        elif key == ord('q'):
            if label_class and len(current_points) == 2:
                objects.append((label_class, current_points.copy()))
                print(f"âœ… Dodano {label_class}")
                current_points = []
                label_class = None

        elif key == ord('n'):
            print("â¡ï¸ nastÄ™pne zdjÄ™cie.")
            break

        elif key == 27:
            print("âŒ Program przerwany przez uÅ¼ytkownika.")
            cv2.destroyAllWindows()
            sys.exit()

    # Zapis danych
    if objects:
        name = os.path.splitext(img_name)[0]

        for label_class, pts in objects:
            x, y, w_box, h_box = normalize_bbox(pts[0], pts[1], w, h)
            class_id = class_map[label_class]
            yolo_line = f"{class_id} {x:.6f} {y:.6f} {w_box:.6f} {h_box:.6f}\n"

            if label_class == 'sneakers':
                out_img = os.path.join(det_folder, 'images', img_name)
                out_txt = os.path.join(det_folder, 'labels', f"{name}.txt")

                with open(out_txt, 'a') as f:
                    f.write(yolo_line)

                shutil.copy(img_path, out_img)

    cv2.destroyAllWindows()

```

```import os, shutil, sys``` â€“ operacje na plikach i folderach, kopiowanie i obsÅ‚uga zakoÅ„czenia programu.

```import cv2``` â€“ biblioteka OpenCV, uÅ¼ywana do wczytywania obrazÃ³w i tworzenia interfejsu graficznego.

```os.makedirs(..., exist_ok=True)``` â€“ tworzy foldery images i labels w katalogu labels, jeÅ›li ich nie ma.

```class_map``` â€“ przypisanie nazw klas do identyfikatorÃ³w liczbowych (tutaj tylko jedna: â€sneakersâ€ = 0).

```normalize_bbox()``` â€“ funkcja przelicza wspÃ³Å‚rzÄ™dne prostokÄ…ta z pikseli na format YOLO:
(x_center, y_center, szerokoÅ›Ä‡, wysokoÅ›Ä‡) â€“ wszystkie wartoÅ›ci znormalizowane (0â€“1).

```cv2.setMouseCallback()``` â€“ rejestruje klikniÄ™cia myszÄ…, ktÃ³re okreÅ›lajÄ… dwa rogi prostokÄ…ta.

```cv2.rectangle() i cv2.imshow()``` â€“ rysuje zaznaczenie na obrazie i wyÅ›wietla je w oknie.

Sterowanie klawiaturÄ…:

```s``` â€“ rozpocznij etykietowanie klasy â€sneakersâ€

```r``` â€“ zresetuj zaznaczenie

```q``` â€“ zatwierdÅº oznaczenie i dodaj do listy

```n``` â€“ przejdÅº do kolejnego obrazu

```ESC``` â€“ zakoÅ„cz program

Zapis wynikÃ³w:


Tworzenie pliku .txt â€“ nazwa etykiety jest taka sama jak nazwa obrazu, ale z rozszerzeniem .txt.

```shutil.copy()``` â€“ kopiuje oryginalny obraz do folderu docelowego (```datasheets/images/[folder]```).

---

### Tworzenie pliku .yaml - wprowadzenie

:point_right: Gdy mamy juÅ¼ przygotowany komplet danych treningowych i walidacyjnych â€“ czyli obrazy wraz z odpowiadajÄ…cymi im etykietami â€“ kolejnym krokiem jest stworzenie pliku konfiguracyjnego .yaml.

Plik .yaml w YOLO peÅ‚ni kluczowÄ… rolÄ™ w procesie trenowania modelu. SÅ‚uÅ¼y do okreÅ›lenia Å›cieÅ¼ek dostÄ™pu do danych treningowych i walidacyjnych (zarÃ³wno obrazÃ³w, jak i etykiet), liczby klas, a takÅ¼e ich nazw. To wÅ‚aÅ›nie ten plik informuje model, z jakim zbiorem danych ma pracowaÄ‡ i czego ma siÄ™ uczyÄ‡.

Plik konfiguracyjny do YOLO
```
train: ./images/train  # ÅšcieÅ¼ka do folderu z obrazami treningowymi
val: ./images/val      # ÅšcieÅ¼ka do folderu z obrazami walidacyjnymi
```
Lista nazw klas w zbiorze danych
```
names:
  0: person
  1: bicycle
  2: car
  3: motorcycle
  4: airplane
  5: bus
  6: train
  7: truck
  8: boat
  9: traffic light
  10: fire hydrant
  # MoÅ¼esz dodaÄ‡ wiÄ™cej klas w zaleÅ¼noÅ›ci od zbioru danych
```
```nc: 11  # Liczba klas obiektÃ³w (np. 11 klas)```

**:point_right: Kluczowe elementy pliku .yaml:**
* **train**: ÅšcieÅ¼ka do folderu z obrazami treningowymi. Zwykle obrazy sÄ… przechowywane w folderze images/train/.

* **val**: ÅšcieÅ¼ka do folderu z obrazami walidacyjnymi. Obrazy walidacyjne sÄ… przechowywane w folderze images/val/.

* **names**: Lista klas, gdzie kaÅ¼da klasa ma przypisanÄ… nazwÄ™. To jest lista obiektÃ³w, ktÃ³re model bÄ™dzie prÃ³bowaÅ‚ wykrywaÄ‡ (np. osoba, rower, samochÃ³d, itp.). Indeksy klas zaczynajÄ… siÄ™ od 0.

* **nc**: Liczba klas w zbiorze danych (np. 11 klas, jeÅ›li chcesz wykrywaÄ‡ 11 rÃ³Å¼nych obiektÃ³w).

Tworzenie pliku .yaml na podstawie etykiet i obrazÃ³w
Aby stworzyÄ‡ plik .yaml na podstawie etykiet i obrazÃ³w w YOLO, musisz wykonaÄ‡ nastÄ™pujÄ…ce kroki:<br>
 **UwzglÄ™dnij obrazy etykietowane rÄ™cznie i automatycznie - finalnie majÄ… one byÄ‡ w jednym folderze**<br>
* Zbierz obrazy: Upewnij siÄ™, Å¼e masz obrazy w odpowiednich folderach. Zazwyczaj struktura katalogÃ³w wyglÄ…da nastÄ™pujÄ…co:<br>

ğŸ“ datasheet
- ğŸ“ images
  - ğŸ“ train
    - ğŸ–¼ï¸ img1.jpg
    - ğŸ–¼ï¸ img2.jpg
  - ğŸ“ val
    - ğŸ–¼ï¸ img3.jpg
    - ğŸ–¼ï¸ img4.jpg
- ğŸ“ labels
  - ğŸ“ train
    - ğŸ“ img1.txt
    - ğŸ“ img2.txt
  - ğŸ“ val
     - ğŸ“ img3.txt
     - ğŸ“ img4.txt

* W folderze **images/train/** znajdujÄ… siÄ™ obrazy do trenowania,
* W folderze **labels/train/** znajdujÄ… siÄ™ pliki tekstowe z etykietami w formacie YOLO (np. image1.txt, image2.txt, itd.). Folder images/val/ i labels/val/ zawierajÄ… obrazy i etykiety do walidacji.

Przygotuj plik z nazwami klas: TwÃ³j plik data.yaml bÄ™dzie musiaÅ‚ zawieraÄ‡ listÄ™ nazw klas w polu names. JeÅ›li masz klasy zapisane w plikach etykiet (np. obiekty w pliku image1.txt), zapisz nazwy klas, ktÃ³re chcesz wykrywaÄ‡, w pliku YAML w sekcji names. <br> 
PrzykÅ‚ad:

names: <br>
  0: person <br>
  1: bicycle <br>
  2: car <br>
  3: motorcycle <br>
  4: airplane <br>

**WskazÃ³wka:** Indeksy klas muszÄ… odpowiadaÄ‡ numerom w etykietach YOLO, czyli klasie 0 odpowiada person, klasie 1 bicycle, itd.
UtwÃ³rz plik .yaml: OtwÃ³rz dowolny edytor tekstu (np. Visual Studio Code, Notepad++) i stwÃ³rz plik data.yaml z odpowiedniÄ… zawartoÅ›ciÄ….

PrzykÅ‚ad pliku data.yaml:

train: /Å›cieÅ¼ka/do/folderu/images/train  # ZastÄ…p Å›cieÅ¼kÄ… do folderu z obrazami treningowymi
val: /Å›cieÅ¼ka/do/folderu/images/val    # ZastÄ…p Å›cieÅ¼kÄ… do folderu z obrazami walidacyjnymi

nc: 5  # Liczba klas (np. jeÅ›li masz 5 klas)
names:
  0: person
  1: bicycle
  2: car
  3: motorcycle
  4: airplane

Uwagi:

* train i val muszÄ… wskazywaÄ‡ na foldery, w ktÃ³rych znajdujÄ… siÄ™ obrazy treningowe i walidacyjne.

* nc to liczba klas w Twoim zbiorze danych (liczba nazw w sekcji names).

* names to lista klas, ktÃ³re chcesz wykrywaÄ‡ (liczby w tej liÅ›cie muszÄ… odpowiadaÄ‡ indeksom klas w etykietach YOLO).

* Zapisz plik: Zapisz plik jako data.yaml w odpowiednim miejscu w Twoim projekcie (np. w folderze z Twoimi danymi lub w folderze yolo/).

KoÅ„cowa struktura powinna wyglÄ…daÄ‡ tak: 

ğŸ“ project_1
  - ğŸ“„ data.yaml
- ğŸ“ images
  - ğŸ“ train
    - ğŸ–¼ï¸ img1.jpg
    - ğŸ–¼ï¸ img2.jpg
  - ğŸ“ val
    - ğŸ–¼ï¸ img3.jpg
    - ğŸ–¼ï¸ img4.jpg
- ğŸ“ labels
  - ğŸ“ train
    - ğŸ“ img1.txt
    - ğŸ“ img2.txt
  - ğŸ“ val
     - ğŸ“ img3.txt
     - ğŸ“ img4.txt

## :three: Fine-tuning modelu
:point_right: **Fine-tuning - proces dalszego treningu modelu, aby poprawiÄ‡ jego wyniki na okreÅ›lonym zbiorze danych, zwÅ‚aszcza jeÅ›li model zostaÅ‚ juÅ¼ wczeÅ›niej wytrenowany na duÅ¼ym zbiorze ogÃ³lnych danych.**
W Ä‡wiczeniu skorzystamy z automatycznego doboru parametrÃ³w dla uczenia maszynowego oferowanego przez funkcjÄ™ `model.tune()`

* Funkcja model.tune() w YOLO (i innych modelach w ultralytics) sÅ‚uÅ¼y do automatycznego dopasowywania hiperparametrÃ³w modelu do danych. WartoÅ›ci, ktÃ³re przekazujesz do tej funkcji, majÄ… duÅ¼y wpÅ‚yw na wydajnoÅ›Ä‡ modelu, czas treningu i jakoÅ›Ä‡ wynikÃ³w. Oto szczegÃ³Å‚owy opis, jak dobraÄ‡ parametry w tej funkcji:
***Parametry funkcji model.tune():***
`data` (data.yaml):
Opis: ÅšcieÅ¼ka do pliku .yaml, ktÃ³ry zawiera informacje o Twoim zbiorze danych, takie jak Å›cieÅ¼ki do folderÃ³w z obrazami treningowymi i walidacyjnymi oraz lista klas obiektÃ³w.

DobÃ³r: Ten parametr jest obowiÄ…zkowy. Plik YAML zawiera wszystkie informacje o danych, ktÃ³re sÄ… niezbÄ™dne do trenowania modelu. Upewnij siÄ™, Å¼e plik data.yaml jest poprawnie skonfigurowany, zawiera odpowiednie Å›cieÅ¼ki do danych i listÄ™ klas.

`epochs (epochs=4)`:

Opis: Liczba epok, czyli liczba peÅ‚nych przejÅ›Ä‡ przez zbiÃ³r treningowy.

DobÃ³r: Liczba epok zaleÅ¼y od wielkoÅ›ci Twojego zbioru danych i zÅ‚oÅ¼onoÅ›ci modelu. Na poczÄ…tek moÅ¼esz zaczÄ…Ä‡ od 10â€“50 epok. JeÅ›li model nie osiÄ…ga dobrych wynikÃ³w, moÅ¼esz zwiÄ™kszyÄ‡ liczbÄ™ epok. Zbyt duÅ¼a liczba epok moÅ¼e prowadziÄ‡ do przeuczenia modelu, dlatego waÅ¼ne jest monitorowanie wynikÃ³w na zbiorze walidacyjnym.

Zalecenie: JeÅ›li masz maÅ‚y zbiÃ³r danych, zacznij od 10-20 epok, a jeÅ›li masz duÅ¼y, zacznij od 50â€“100 epok i monitoruj postÄ™p.

`iterations (iterations=1):`

Opis: Liczba iteracji, ktÃ³re pozwalajÄ… na znalezienie optymalnych hiperparametrÃ³w.

DobÃ³r: WartoÅ›Ä‡ ta jest uÅ¼ywana w przypadku automatycznego dostosowywania hiperparametrÃ³w. DomyÅ›lnie jest ustawiona na 1, co oznacza, Å¼e model nie bÄ™dzie wykonywaÅ‚ optymalizacji hiperparametrÃ³w. JeÅ›li chcesz, aby model zoptymalizowaÅ‚ swoje hiperparametry, zwiÄ™ksz tÄ™ wartoÅ›Ä‡. Zbyt duÅ¼a liczba iteracji moÅ¼e jednak prowadziÄ‡ do wydÅ‚uÅ¼enia czasu treningu bez zauwaÅ¼alnej poprawy wynikÃ³w.

Zalecenie: JeÅ›li chcesz przeprowadziÄ‡ eksperymenty z optymalizacjÄ… hiperparametrÃ³w, uÅ¼yj wartoÅ›ci 2 lub 3 dla iterations. Jednak dla prostych zastosowaÅ„, wartoÅ›Ä‡ 1 moÅ¼e byÄ‡ wystarczajÄ…ca.

`imgsz (imgsz=640):`

Opis: Rozmiar obrazu, na ktÃ³rym model bÄ™dzie pracowaÄ‡. MoÅ¼e to byÄ‡ wartoÅ›Ä‡ w pikselach, np. 640x640 px.

DobÃ³r: WiÄ™kszy rozmiar obrazu pozwala na lepsze wykrywanie szczegÃ³Å‚Ã³w, ale takÅ¼e zwiÄ™ksza zapotrzebowanie na pamiÄ™Ä‡ GPU i wydÅ‚uÅ¼a czas obliczeÅ„. Typowo, dla YOLOv5 uÅ¼ywa siÄ™ rozmiarÃ³w 640x640 px lub 416x416 px. MoÅ¼esz sprÃ³bowaÄ‡ rÃ³Å¼nych rozmiarÃ³w w zaleÅ¼noÅ›ci od zasobÃ³w, jakie posiadasz.

Zalecenie: Rozpocznij od wartoÅ›ci 640, jeÅ›li masz wystarczajÄ…co duÅ¼o pamiÄ™ci GPU. W przypadku ograniczeÅ„ pamiÄ™ci, zmniejszenie rozmiaru do 416 moÅ¼e pomÃ³c.

`batch (batch=16):`

Opis: Rozmiar batcha, czyli liczba obrazÃ³w przetwarzanych rÃ³wnoczeÅ›nie w jednym kroku podczas treningu.

DobÃ³r: ZwiÄ™kszenie rozmiaru batcha moÅ¼e przyspieszyÄ‡ trening (szczegÃ³lnie na GPU), ale wymaga wiÄ™cej pamiÄ™ci. Optymalna wartoÅ›Ä‡ zaleÅ¼y od dostÄ™pnej pamiÄ™ci GPU. Standardowe wartoÅ›ci to 8, 16, 32.

Zalecenie: Zacznij od rozmiaru batcha 16. JeÅ›li TwÃ³j GPU ma ograniczonÄ… pamiÄ™Ä‡, sprÃ³buj z mniejszym rozmiarem batcha, np. 8.

`device (device=device):`

Opis: UrzÄ…dzenie, na ktÃ³rym ma odbywaÄ‡ siÄ™ trening. MoÅ¼esz wybraÄ‡ cpu lub cuda (jeÅ›li masz GPU).

DobÃ³r: JeÅ›li masz dostÄ™p do GPU, zawsze wybieraj cuda, poniewaÅ¼ pozwoli to znacznie przyspieszyÄ‡ trening. JeÅ›li nie masz GPU, uÅ¼ywaj cpu.

Zalecenie: UÅ¼ywaj cuda jeÅ›li masz kartÄ™ graficznÄ… kompatybilnÄ… z CUDA. Dla CPU uÅ¼yj cpu, chociaÅ¼ trening na CPU moÅ¼e byÄ‡ znacznie wolniejszy.

`workers (workers=8):`

Opis: Liczba wÄ…tkÃ³w do wczytywania danych.

DobÃ³r: OkreÅ›la, ile wÄ…tkÃ³w procesora zostanie uÅ¼ytych do rÃ³wnoczesnego Å‚adowania danych. WiÄ™ksza liczba wÄ…tkÃ³w moÅ¼e przyspieszyÄ‡ Å‚adowanie danych, ale zaleÅ¼y to od wydajnoÅ›ci Twojego CPU. JeÅ›li masz 8 rdzeni CPU, uÅ¼ycie wartoÅ›ci 8 lub 4 moÅ¼e byÄ‡ dobrym wyborem.

Zalecenie: Zaczynaj od wartoÅ›ci 8, a jeÅ›li zauwaÅ¼ysz problemy z wydajnoÅ›ciÄ… CPU, zmniejsz tÄ™ wartoÅ›Ä‡ (np. do 4).

`augment (augment=True):`

Opis: WÅ‚Ä…czenie augmentacji danych, czyli sztucznego zwiÄ™kszania rozmiaru zbioru danych poprzez rÃ³Å¼ne transformacje obrazÃ³w (np. obrÃ³t, przyciÄ™cie, zmiany jasnoÅ›ci, kontrastu, itp.).

DobÃ³r: Augmentacja pomaga zwiÄ™kszyÄ‡ rÃ³Å¼norodnoÅ›Ä‡ danych treningowych i moÅ¼e poprawiÄ‡ wyniki modelu, zwÅ‚aszcza gdy masz maÅ‚y zbiÃ³r danych. W wiÄ™kszoÅ›ci przypadkÃ³w warto jÄ… wÅ‚Ä…czyÄ‡, ale moÅ¼e zwiÄ™kszyÄ‡ czas treningu.

Zalecenie: UÅ¼ywaj augment=True, chyba Å¼e masz bardzo duÅ¼Ä… iloÅ›Ä‡ danych, w ktÃ³rym to przypadku augmentacja moÅ¼e nie byÄ‡ konieczna.

`project (project='...results/xyz'):`

Opis: Folder, w ktÃ³rym bÄ™dÄ… zapisywane wyniki treningu, w tym wykresy, model, logi itd.

DobÃ³r: Musisz okreÅ›liÄ‡ folder, w ktÃ³rym chcesz przechowywaÄ‡ wyniki. MoÅ¼esz podaÄ‡ Å›cieÅ¼kÄ™ do dowolnego katalogu na swoim dysku.

Zalecenie: UÅ¼yj unikalnej Å›cieÅ¼ki dla kaÅ¼dego eksperymentu, aby Å‚atwo rozrÃ³Å¼niaÄ‡ wyniki rÃ³Å¼nych sesji treningowych.

`name (name='lab3_a'):`

Opis: Nazwa eksperymentu, ktÃ³ra bÄ™dzie uÅ¼ywana do oznaczenia folderu wynikÃ³w.

DobÃ³r: MoÅ¼e to byÄ‡ dowolna nazwa, np. nazwa eksperymentu, data, itp.

Zalecenie: UÅ¼ywaj nazw, ktÃ³re pomagajÄ… Ci Å‚atwo zidentyfikowaÄ‡ dany eksperyment. Na przykÅ‚ad, jeÅ›li trenujesz model na detekcji rÃ³Å¼nych obiektÃ³w, uÅ¼yj nazwy zwiÄ…zanej z tym zadaniem, np. figury_UNITY.

### :star: Podsumowanie:

* Liczba epok: ZwiÄ™kszaj, jeÅ›li model nie konwerguje po kilku epokach.

* Iterations: Ustaw na 1, chyba Å¼e eksperymentujesz z automatycznym dostosowywaniem hiperparametrÃ³w.

* Rozmiar obrazu: Standardowo 640, ale moÅ¼esz zmniejszyÄ‡, jeÅ›li masz ograniczonÄ… pamiÄ™Ä‡ GPU.

* Rozmiar batcha: Zaczynaj od 16, ale dostosuj do dostÄ™pnej pamiÄ™ci.

* Device: UÅ¼ywaj cuda dla GPU, cpu dla CPU.

* Workers: ZwiÄ™kszaj, jeÅ›li masz wydajny CPU.

* Augmentacja: Zalecana, zwÅ‚aszcza przy maÅ‚ych zbiorach danych.

**KaÅ¼dy z tych parametrÃ³w ma wpÅ‚yw na czas treningu oraz jakoÅ›Ä‡ wynikÃ³w. Warto testowaÄ‡ rÃ³Å¼ne kombinacje, aby znaleÅºÄ‡ najlepszÄ… dla swojego przypadku.**

* **przykÅ‚adowy skrypt `train_own_model.py`**

```python
if __name__ == '__main__':
    from ultralytics import YOLO
    import torch
    import time
    model_path = r'yolov5su.pt'
    model = YOLO(model_path)

    # Automatyczne wykrywanie GPU
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    model.to(device)
    start = time.time()
    # # Tuning hiperparametrÃ³w - Automatyczne dostosowywanie
    model.tune(
        data='data.yaml',   # Plik konfiguracyjny danych
        epochs=4,          # Liczba epok 50
        iterations=1,      # Liczba iteracji, ktÃ³re pozwalajÄ… na znalezienie optymalnych hiperparametrÃ³w 2
        imgsz=640,          # Rozmiar obrazu
        batch=16,            # Rozmiar batcha
        device=device,      # WybÃ³r urzÄ…dzenia (GPU/CPU)
        workers=8,          # Liczba wÄ…tkÃ³w do wczytywania danych
        augment=True,       # Augmentacja
        project='../results/xyz', # Folder zapisu wynikÃ³w
        name='exp_1'    # Nazwa eksperymentu
    )

```
Po uruchomieniu kodu z funkcjÄ… model.tune(), zakÅ‚adajÄ…c, Å¼e dane sÄ… poprawnie przygotowane (tzn. obrazy oraz etykiety w odpowiednich formatach i pliku data.yaml sÄ… dobrze skonfigurowane), wynik dziaÅ‚ania tego kodu powinien obejmowaÄ‡:

* **1. Trening modelu YOLOv5:**
Model zostanie wytrenowany przy uÅ¼yciu dostarczonych danych treningowych (obrazÃ³w i etykiet).

* Automatyczne dostosowywanie hiperparametrÃ³w: Funkcja `model.tune()` bÄ™dzie prÃ³bowaÅ‚a optymalizowaÄ‡ hiperparametry 
modelu (np. rozmiar batcha, liczba epok, augmentacja) w ramach podanych iteracji. JeÅ›li nie ustawisz wartoÅ›ci wiÄ™kszej niÅ¼ 1 dla 
`iterations`, to hiperparametry nie bÄ™dÄ… dostosowywane, a trening bÄ™dzie wykonywany z domyÅ›lnymi ustawieniami.

* Rozpocznie trening modelu z okreÅ›lonÄ… liczbÄ… epok (np. 4) oraz przy innych zadanych parametrach.

* Wykorzystanie GPU/CPU: W zaleÅ¼noÅ›ci od tego, czy masz dostÄ™p do GPU, model zostanie uruchomiony na odpowiednim urzÄ…dzeniu (cuda lub cpu).

* **2. Monitoring procesu treningu:**
* Wydruk wynikÃ³w: Podczas treningu bÄ™dÄ… wyÅ›wietlane informacje o postÄ™pie, takie jak:
  * Strata (`loss`) na zbiorze treningowym oraz walidacyjnym.
  * Czas treningu.
  * WartoÅ›ci metryk (np. `mAP - mean Average Precision`) dla wykrywania obiektÃ³w.

PrzykÅ‚ad konsoli:

```bash 
Epoch [1/4] | Training loss: 0.34 | Validation loss: 0.28 | mAP@0.5: 0.85 | mAP@0.75: 0.72
Epoch [2/4] | Training loss: 0.30 | Validation loss: 0.26 | mAP@0.5: 0.87 | mAP@0.75: 0.74
Epoch [3/4] | Training loss: 0.27 | Validation loss: 0.25 | mAP@0.5: 0.88 | mAP@0.75: 0.75
Epoch [4/4] | Training loss: 0.24 | Validation loss: 0.22 | mAP@0.5: 0.90 | mAP@0.75: 0.78
```
* Strata (`Loss`): Z kaÅ¼dym krokiem treningu bÄ™dzie wyÅ›wietlana wartoÅ›Ä‡ straty, zarÃ³wno na zbiorze treningowym, jak i walidacyjnym. Strata powinna maleÄ‡, co oznacza, Å¼e model siÄ™ "uczy".

* Wyniki `mAP` (mean Average Precision): Podczas treningu i po zakoÅ„czeniu kaÅ¼dej epoki bÄ™dzie podawana wartoÅ›Ä‡ mAP na zbiorze walidacyjnym (im wyÅ¼sza wartoÅ›Ä‡, tym lepszy model).

* **3. Wyniki zapisywane do folderu wynikÃ³w:** 
  * Po zakoÅ„czeniu treningu, wszystkie wyniki zostanÄ… zapisane w folderze okreÅ›lonym w parametrze project, w tym:
    * Modele (np. best.pt, last.pt) zapisane w folderze runs/train/exp/weights/.
      * Logi z treningu zapisane w plikach .txt w folderze runs/train/exp/. 
      * Wykresy (np. wykresy straty i metryk) zapisane w folderze runs/train/exp/plots/.

**struktura folderu wynikÃ³w:** 
* :open_file_folder: results
  * :open_file_folder: results/xyz
    * :open_file_folder: runs
      * :open_file_folder:exp_1
        * :file_folder: weights
          * :large_blue_diamond: best.py
          * :large_blue_diamond: last.pt
        * :file_folder: logs
          * ğŸ“„ train.txt
        * :file_folder: plots
          * ğŸ–¼ï¸ loss.png
          * ğŸ–¼ï¸ metrics.png
 

* **4. Wynik w oknie graficznym:**
`results.show()`: JeÅ›li ten parametr jest aktywowany, wyniki bÄ™dÄ… takÅ¼e wyÅ›wietlane w oknie graficznym. BÄ™dziesz mÃ³gÅ‚ zobaczyÄ‡ obrazy z detekcjami obiektÃ³w na przykÅ‚adzie kilku obrazÃ³w z zbioru walidacyjnego.

PrzykÅ‚ad: Na obrazach zostanÄ… narysowane prostokÄ…ty wokÃ³Å‚ wykrytych obiektÃ³w, a takÅ¼e zostanÄ… wyÅ›wietlone ich klasy i prawdopodobieÅ„stwa detekcji.

* **5. Czas treningu:**
Zmienna start rejestruje czas rozpoczÄ™cia treningu, a po zakoÅ„czeniu procesu wyÅ›wietli czas trwania treningu.

**PrzykÅ‚ad:**

* Czas treningu: 240.123 sekundy
**Potencjalne problemy:**
  * BrakujÄ…ce dane: JeÅ›li foldery z obrazami lub etykietami sÄ… nieprawidÅ‚owe lub puste, lub jeÅ›li dane w plikach .txt sÄ… Åºle sformatowane (np. zÅ‚e klasy lub niepoprawne wspÃ³Å‚rzÄ™dne prostokÄ…tÃ³w), model moÅ¼e zakoÅ„czyÄ‡ trening z bÅ‚Ä™dami lub nie osiÄ…gnÄ…Ä‡ dobrych wynikÃ³w.

  * BÅ‚Ä™dy w pliku data.yaml: JeÅ›li plik data.yaml jest Åºle skonfigurowany (np. niepoprawne Å›cieÅ¼ki do folderÃ³w, brak klas), trening moÅ¼e zakoÅ„czyÄ‡ siÄ™ niepowodzeniem.

  * Zbyt maÅ‚a liczba epok: JeÅ›li liczba epok jest zbyt maÅ‚a (np. 4 epoki), model moÅ¼e nie mieÄ‡ wystarczajÄ…co czasu na naukÄ™, co prowadzi do sÅ‚abych wynikÃ³w.

**:bulb:  Podsumowanie:** 
* Po poprawnym uruchomieniu kodu, wynik bÄ™dzie obejmowaÄ‡:
  * Wyniki treningu i walidacji na kaÅ¼dej epoce (strata, mAP, itp.). 
  * Modele zapisane w folderze wynikÃ³w (best.pt, last.pt).

* Wykresy i logi procesu treningu. 
  * Czas trwania treningu.
  *(Opcjonalnie) Obrazy z detekcjami wyÅ›wietlane w oknie graficznym.

**Wyniki treningu bÄ™dÄ… zaleÅ¼ne od jakoÅ›ci danych (obrazÃ³w i etykiet), liczby epok oraz innych hiperparametrÃ³w, ktÃ³re ustawiÅ‚eÅ›.** 

### Sprawdzenie dokÅ‚adnoÅ›ci modelu

Ostatni krok to sprawdzenie dokÅ‚adnoÅ›ci modelu:
```python
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
path = r"C:\...\weights\best.pt"
model = YOLO(path)
img_path = r"example_image"
img = cv2.imread(img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Konwersja do RGB dla poprawnego wyÅ›wietlania
results = model(img_path)
annotated_img = results[0].plot()  # Narysuj wykryte obiekty na obrazie
plt.imshow(annotated_img)
plt.axis('off')
plt.show()
```

### WyjaÅ›nienie: 

`YOLO` z `ultralytics` - Importuje klasÄ™ do uÅ¼ywania modeli YOLOv5.

`cv2 (OpenCV)` - UÅ¼ywane do wczytywania i przetwarzania obrazÃ³w.

`matplotlib.pyplot` - UÅ¼ywane do wyÅ›wietlania obrazÃ³w z detekcjami w oknie graficznym.

`model` - Wczytuje zapisany model YOLOv5 z pliku .pt, ktÃ³ry znajduje siÄ™ w Å›cieÅ¼ce okreÅ›lonej przez zmiennÄ… path. Ten plik zawiera wagi wytrenowanego modelu. Model ten bÄ™dzie wykorzystywany do detekcji obiektÃ³w na obrazie.

`cv2.imread` - Wczytuje obraz z dysku za pomocÄ… OpenCV (funkcja cv2.imread). ÅšcieÅ¼ka do obrazu jest okreÅ›lona przez zmiennÄ… img_path. Obraz jest Å‚adowany w formacie BGR, co jest standardem w OpenCV.

`cv2.cvtColor(img, cv2.COLOR_BGR2RGB)` - OpenCV domyÅ›lnie uÅ¼ywa formatu BGR, ale dla poprawnego wyÅ›wietlania w matplotlib, obraz musi byÄ‡ w formacie RGB. Ta linia kodu konwertuje obraz z BGR na RGB.

`results` - Przekazuje obraz do modelu YOLOv5, aby przeprowadziÄ‡ detekcjÄ™ obiektÃ³w.

Wyniki sÄ… zapisane w obiekcie `results`, ktÃ³ry zawiera wykryte obiekty, w tym ich wspÃ³Å‚rzÄ™dne i klasy.

`annotated_img` = Ta linia rysuje prostokÄ…ty wokÃ³Å‚ wykrytych obiektÃ³w na obrazie. Funkcja `plot()` automatycznie dodaje adnotacje, takie jak klasy wykrytych obiektÃ³w i ich prawdopodobieÅ„stwa, na oryginalnym obrazie. 
`results[0]` odnosi siÄ™ do pierwszego (i czÄ™sto jedynego) obrazu w wynikach, poniewaÅ¼ funkcja detekcji jest uruchamiana na jednym obrazie.
`plt.imshow(annotated_img)` - WyÅ›wietla obraz z wykrytymi obiektami.

`plt.axis('off')` - Ukrywa osie wykresu (aby obraz byÅ‚ wyÅ›wietlany bez zbÄ™dnych oznaczeÅ„ osi).

`plt.show()` - Pokazuje okno z obrazem.

* Co otrzymasz w wyniku dziaÅ‚ania tego kodu:
  * Na obrazie bÄ™dÄ… narysowane prostokÄ…ty wokÃ³Å‚ wykrytych obiektÃ³w, a takÅ¼e ich etykiety oraz prawdopodobieÅ„stwa detekcji. 
  * Obraz zostanie wyÅ›wietlony w oknie graficznym (dziÄ™ki `matplotlib`), co pozwala na wizualnÄ… weryfikacjÄ™ wynikÃ³w detekcji.


# Praca z danymi wirtualnymi

